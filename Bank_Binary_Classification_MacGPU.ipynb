{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb92834",
   "metadata": {},
   "source": [
    "\n",
    "# 🏦 Binary Classification with a Bank Dataset (Kaggle Playground S5E8) — macOS (VS Code)\n",
    "\n",
    "This notebook gives you an **end-to-end, well-structured pipeline**:\n",
    "- Data loading (local or Kaggle CLI)\n",
    "- Minimal feature engineering\n",
    "- **CatBoost** (CPU) with robust Stratified K-Fold CV\n",
    "- **LightGBM** (CPU) with native categoricals\n",
    "- Simple **blend** for better AUC\n",
    "- Optional **PyTorch MLP** that runs on **Apple GPU (MPS)** (note: NNs may underperform gradient boosting on this dataset, but this shows GPU usage on Mac)\n",
    "\n",
    "> **GPU note for macOS:** CatBoost/LightGBM GPU backends require CUDA/OpenCL and **do not use Apple's MPS**. So tree models here run on CPU. The **optional PyTorch** section demonstrates Apple GPU (MPS) acceleration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0cdd5",
   "metadata": {},
   "source": [
    "## 0. Hardware & Environment Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9202da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 10:07:17) [Clang 14.0.6 ]\n",
      "OS: macOS-15.6-arm64-arm-64bit\n",
      "Machine: arm64\n",
      "Processor: arm\n",
      "kaggle CLI available: True\n",
      "PyTorch version: 2.8.0\n",
      "Apple GPU (MPS) available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import platform, sys, subprocess, shutil\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Machine:\", platform.machine())\n",
    "print(\"Processor:\", platform.processor())\n",
    "\n",
    "# Optional: check if kaggle CLI exists (installed via pip or system)\n",
    "print(\"kaggle CLI available:\", shutil.which(\"kaggle\") is not None)\n",
    "\n",
    "# Optional: check for PyTorch + MPS (Apple GPU)\n",
    "try:\n",
    "    import torch\n",
    "    mps_ok = hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Apple GPU (MPS) available:\", mps_ok)\n",
    "except Exception as e:\n",
    "    print(\"PyTorch not installed or import failed. MPS check skipped.\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59670d8",
   "metadata": {},
   "source": [
    "## 1. Install/Verify Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf096f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in ./.venv/lib/python3.12/site-packages (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: catboost in ./.venv/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: lightgbm in ./.venv/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: xgboost in ./.venv/lib/python3.12/site-packages (3.0.4)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.12/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from catboost) (3.10.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./.venv/lib/python3.12/site-packages (from catboost) (2.3.2)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.venv/lib/python3.12/site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from catboost) (1.16.1)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.12/site-packages (from catboost) (6.3.0)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.12/site-packages (from plotly->catboost) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If you already have these, you can skip. VS Code often handles envs well.\n",
    "# Run these one by one if you prefer.\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U numpy pandas scikit-learn matplotlib\n",
    "%pip install -U catboost lightgbm xgboost\n",
    "# Optional (for Apple GPU demo with a simple MLP):\n",
    "%pip install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "# ^ On macOS, PyTorch wheel will include MPS if running on Apple Silicon + macOS 12.3+.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491eed85",
   "metadata": {},
   "source": [
    "## 2. Data: Local Path or Kaggle Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef8ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/Users/sanyuktatuti/Documents/Bank_Binary_Classification/.kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b167c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to: /Users/sanyuktatuti/Documents/Bank_Binary_Classification/data\n",
      "Downloading playground-series-s5e8.zip to data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14.7M/14.7M [00:00<00:00, 2.85GB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Kaggle files ready: ['train.csv', 'test.csv', 'sample_submission.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ Robust Kaggle download for VS Code/macOS using the Kaggle Python API (no shell CLI)\n",
    "\n",
    "from pathlib import Path\n",
    "import os, stat, zipfile, glob\n",
    "\n",
    "# Where to put the CSVs\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If you keep your token in the project, export this before running (or set it here):\n",
    "# os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/Users/sanyuktatuti/Documents/Bank_Binary_Classification/.kaggle\"\n",
    "\n",
    "# Fallback to ~/.kaggle if KAGGLE_CONFIG_DIR not set\n",
    "cfg_dir = Path(os.environ.get(\"KAGGLE_CONFIG_DIR\", Path.home() / \".kaggle\"))\n",
    "cfg_dir.mkdir(parents=True, exist_ok=True)\n",
    "token = cfg_dir / \"kaggle.json\"\n",
    "if not token.exists():\n",
    "    raise SystemExit(\n",
    "        f\"kaggle.json not found at {token}.\\n\"\n",
    "        \"Download from https://www.kaggle.com/settings (Create New API Token) and place it there.\\n\"\n",
    "        \"Or set os.environ['KAGGLE_CONFIG_DIR'] to your project .kaggle folder.\"\n",
    "    )\n",
    "# Fix permissions (Kaggle requires 600)\n",
    "token.chmod(stat.S_IRUSR | stat.S_IWUSR)\n",
    "\n",
    "# Make sure 'kaggle' package is installed in THIS kernel/env\n",
    "import sys, subprocess\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", \"kaggle\"], check=True)\n",
    "\n",
    "# Use the official Python API (avoids broken shell scripts)\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "print(\"Downloading to:\", DATA_DIR.resolve())\n",
    "api.competition_download_files(\"playground-series-s5e8\", path=str(DATA_DIR), quiet=False)\n",
    "\n",
    "# Unzip everything we just downloaded\n",
    "zips = sorted(glob.glob(str(DATA_DIR / \"*.zip\")))\n",
    "if not zips:\n",
    "    raise SystemExit(\"No ZIPs found after download — check auth output above.\")\n",
    "for z in zips:\n",
    "    with zipfile.ZipFile(z) as zf:\n",
    "        zf.extractall(DATA_DIR)\n",
    "\n",
    "# Verify expected files\n",
    "expected = [\"train.csv\", \"test.csv\", \"sample_submission.csv\"]\n",
    "missing = [f for f in expected if not (DATA_DIR / f).exists()]\n",
    "if missing:\n",
    "    raise SystemExit(f\"Missing files after unzip: {missing}\")\n",
    "print(\"✅ Kaggle files ready:\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f0a520",
   "metadata": {},
   "source": [
    "## 3. Load Data & Quick Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b787ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 18) (250000, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>25</td>\n",
       "      <td>aug</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>514</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>jun</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>602</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>may</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>may</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>889</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>feb</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age          job  marital  education default  balance housing loan  \\\n",
       "0   0   42   technician  married  secondary      no        7      no   no   \n",
       "1   1   38  blue-collar  married  secondary      no      514      no   no   \n",
       "2   2   36  blue-collar  married  secondary      no      602     yes   no   \n",
       "3   3   27      student   single  secondary      no       34     yes   no   \n",
       "4   4   26   technician  married  secondary      no      889     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0  cellular   25   aug       117         3     -1         0  unknown  0  \n",
       "1   unknown   18   jun       185         1     -1         0  unknown  0  \n",
       "2   unknown   14   may       111         2     -1         0  unknown  0  \n",
       "3   unknown   28   may        10         2     -1         0  unknown  0  \n",
       "4  cellular    3   feb       902         1     -1         0  unknown  1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, pathlib\n",
    "DATA_DIR = pathlib.Path(\"./data\")\n",
    "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "test  = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "sample= pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed798b",
   "metadata": {},
   "source": [
    "## 4. Tiny Feature Engineering (cheap but helpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c437f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered columns added. Example:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdays_is_neg1</th>\n",
       "      <th>has_previous</th>\n",
       "      <th>balance_sign</th>\n",
       "      <th>month</th>\n",
       "      <th>month_idx</th>\n",
       "      <th>age</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>campaign</th>\n",
       "      <th>campaign_cap</th>\n",
       "      <th>pdays</th>\n",
       "      <th>pdays_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pos</td>\n",
       "      <td>aug</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>(35, 45]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>(-2, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pos</td>\n",
       "      <td>jun</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>(35, 45]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(-2, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pos</td>\n",
       "      <td>may</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>(35, 45]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>(-2, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pos</td>\n",
       "      <td>may</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>(25, 35]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>(-2, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pos</td>\n",
       "      <td>feb</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>(25, 35]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(-2, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdays_is_neg1 has_previous balance_sign month  month_idx  age   age_bin  \\\n",
       "0          True        False          pos   aug          8   42  (35, 45]   \n",
       "1          True        False          pos   jun          6   38  (35, 45]   \n",
       "2          True        False          pos   may          5   36  (35, 45]   \n",
       "3          True        False          pos   may          5   27  (25, 35]   \n",
       "4          True        False          pos   feb          2   26  (25, 35]   \n",
       "\n",
       "   campaign  campaign_cap  pdays pdays_bin  \n",
       "0         3             3     -1  (-2, -1]  \n",
       "1         1             1     -1  (-2, -1]  \n",
       "2         2             2     -1  (-2, -1]  \n",
       "3         2             2     -1  (-2, -1]  \n",
       "4         1             1     -1  (-2, -1]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "for df in (train, test):\n",
    "    # Special code used in bank-style data\n",
    "    df[\"pdays_is_neg1\"] = (df[\"pdays\"] == -1).astype(\"str\")\n",
    "    # Whether any previous contacts exist\n",
    "    df[\"has_previous\"]  = (df[\"previous\"] > 0).astype(\"str\")\n",
    "    # Balance sign bucket\n",
    "    df[\"balance_sign\"]  = np.where(df[\"balance\"] < 0, \"neg\",\n",
    "                            np.where(df[\"balance\"] == 0, \"zero\", \"pos\")).astype(\"str\")\n",
    "    # Extra small features\n",
    "    month_order = {'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,\n",
    "                   'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12}\n",
    "    df[\"month_idx\"]   = df[\"month\"].map(month_order).fillna(0).astype(int)\n",
    "    df[\"age_bin\"]     = pd.cut(df[\"age\"], bins=[-1,25,35,45,55,65,120]).astype(str)\n",
    "    df[\"campaign_cap\"]= np.minimum(df[\"campaign\"], 10).astype(int)\n",
    "    df[\"pdays_bin\"]   = pd.cut(df[\"pdays\"], bins=[-2,-1,5,30,90,365,100000], right=True).astype(str)\n",
    "\n",
    "print(\"Engineered columns added. Example:\")\n",
    "display(train[[\"pdays_is_neg1\",\"has_previous\",\"balance_sign\",\"month\",\"month_idx\",\"age\",\"age_bin\",\"campaign\",\"campaign_cap\",\"pdays\",\"pdays_bin\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd74f5",
   "metadata": {},
   "source": [
    "## 5. Prepare Features & Inferred Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56ec76e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC(duration raw): 0.8895128234037682\n",
      "AUC(log1p(duration)): 0.8895128234037682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "d = pd.to_numeric(train[\"duration\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "print(\"AUC(duration raw):\", roc_auc_score(y, d))\n",
    "print(\"AUC(log1p(duration)):\", roc_auc_score(y, np.log1p(d.clip(lower=0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85cea4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iso-Global] raw=0.891598 log1p=0.891598 → blended=0.891598\n",
      "[Iso-contact] OOF AUC=0.500000 | groups kept>=2000: 3\n",
      "[Iso-month] OOF AUC=0.500000 | groups kept>=2000: 12\n",
      "[Iso-DUR*] best OOF AUC=0.891598 at (w_global=0.10, w_contact=0.00, w_month=0.90)\n",
      "Wrote submission_duration_iso_contact_month.csv\n",
      "[Blend3] best OOF AUC=0.956735 via mean(wcb=0.025,wlgb=0.050,wdur=0.925)\n",
      "Wrote submission_rank_or_mean_blend_cb_lgb_dur.csv\n",
      "[Meta-LR KFold] OOF AUC=0.958932\n",
      "Wrote submission_meta_lr_kfold_cb_lgb_dur.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "assert \"duration\" in train.columns, \"duration missing. Rebuild features with DROP_DURATION=False.\"\n",
    "\n",
    "FOLDS = 10\n",
    "rs = 42\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=rs)\n",
    "\n",
    "dur_tr = train[\"duration\"].astype(float).to_numpy()\n",
    "dur_te = test[\"duration\"].astype(float).to_numpy()\n",
    "y_arr  = y.values\n",
    "contact_tr = train[\"contact\"].astype(str).fillna(\"NA\").values\n",
    "contact_te = test[\"contact\"].astype(str).fillna(\"NA\").values\n",
    "month_tr   = train[\"month\"].astype(str).fillna(\"NA\").values\n",
    "month_te   = test[\"month\"].astype(str).fillna(\"NA\").values\n",
    "\n",
    "def rankit(a):\n",
    "    return pd.Series(a).rank(method=\"average\").to_numpy() / (len(a)+1e-9)\n",
    "\n",
    "# 1) Global isotonic (raw + log1p), blended\n",
    "oof_raw  = np.zeros_like(dur_tr, dtype=np.float32); pred_raw  = np.zeros_like(dur_te, dtype=np.float32)\n",
    "oof_log  = np.zeros_like(dur_tr, dtype=np.float32); pred_log  = np.zeros_like(dur_te, dtype=np.float32)\n",
    "for tr_idx, va_idx in skf.split(dur_tr.reshape(-1,1), y_arr):\n",
    "    ir = IsotonicRegression(out_of_bounds=\"clip\").fit(dur_tr[tr_idx], y_arr[tr_idx])\n",
    "    oof_raw[va_idx]  = ir.predict(dur_tr[va_idx]);  pred_raw += ir.predict(dur_te)/FOLDS\n",
    "    ir2 = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    xtr = np.log1p(np.clip(dur_tr[tr_idx],0,None)); xva = np.log1p(np.clip(dur_tr[va_idx],0,None)); xte = np.log1p(np.clip(dur_te,0,None))\n",
    "    ir2.fit(xtr, y_arr[tr_idx])\n",
    "    oof_log[va_idx]  = ir2.predict(xva);           pred_log += ir2.predict(xte)/FOLDS\n",
    "\n",
    "auc_raw = roc_auc_score(y_arr, oof_raw)\n",
    "auc_log = roc_auc_score(y_arr, oof_log)\n",
    "w_raw = 0.5 if abs(auc_raw-auc_log)<0.002 else (1.0 if auc_raw>auc_log else 0.0)\n",
    "oof_iso_global  = w_raw*oof_raw + (1-w_raw)*oof_log\n",
    "pred_iso_global = w_raw*pred_raw + (1-w_raw)*pred_log\n",
    "print(f\"[Iso-Global] raw={auc_raw:.6f} log1p={auc_log:.6f} → blended={roc_auc_score(y_arr,oof_iso_global):.6f}\")\n",
    "\n",
    "# 2) Grouped isotonic — per contact and per month, fold-safe OOF with global fallback\n",
    "def grouped_iso_oof_pred(groups_tr, groups_te, min_group=2000, label=\"contact\"):\n",
    "    oof_g = np.zeros_like(dur_tr, dtype=np.float32)\n",
    "    pred_g = np.zeros_like(dur_te, dtype=np.float32)\n",
    "    for tr_idx, va_idx in skf.split(dur_tr.reshape(-1,1), y_arr):\n",
    "        g_ir = IsotonicRegression(out_of_bounds=\"clip\").fit(dur_tr[tr_idx], y_arr[tr_idx])  # fallback\n",
    "        per = {}\n",
    "        for g in np.unique(groups_tr[tr_idx]):\n",
    "            m = (groups_tr[tr_idx]==g)\n",
    "            if m.sum() >= min_group:\n",
    "                per[g] = IsotonicRegression(out_of_bounds=\"clip\").fit(dur_tr[tr_idx][m], y_arr[tr_idx][m])\n",
    "        # OOF for this fold\n",
    "        for g in np.unique(groups_tr[va_idx]):\n",
    "            m = (groups_tr[va_idx]==g)\n",
    "            model = per.get(g, g_ir)\n",
    "            oof_g[va_idx][m] = model.predict(dur_tr[va_idx][m])\n",
    "    # Test using full train fit\n",
    "    g_ir_full = IsotonicRegression(out_of_bounds=\"clip\").fit(dur_tr, y_arr)\n",
    "    per_full = {}\n",
    "    for g in np.unique(groups_tr):\n",
    "        m = (groups_tr==g)\n",
    "        if m.sum() >= min_group:\n",
    "            per_full[g] = IsotonicRegression(out_of_bounds=\"clip\").fit(dur_tr[m], y_arr[m])\n",
    "    for g in np.unique(groups_te):\n",
    "        m = (groups_te==g)\n",
    "        model = per_full.get(g, g_ir_full)\n",
    "        pred_g[m] = model.predict(dur_te[m])\n",
    "    auc = roc_auc_score(y_arr, oof_g)\n",
    "    print(f\"[Iso-{label}] OOF AUC={auc:.6f} | groups kept>={min_group}: {len(per_full)}\")\n",
    "    return oof_g, pred_g\n",
    "\n",
    "oof_iso_contact, pred_iso_contact = grouped_iso_oof_pred(contact_tr, contact_te, min_group=2000, label=\"contact\")\n",
    "oof_iso_month,   pred_iso_month   = grouped_iso_oof_pred(month_tr,   month_te,   min_group=2000, label=\"month\")\n",
    "\n",
    "# Combine duration channels (global + contact + month)\n",
    "dur_channels = {\n",
    "    \"global\": (oof_iso_global,  pred_iso_global),\n",
    "    \"contact\":(oof_iso_contact, pred_iso_contact),\n",
    "    \"month\":  (oof_iso_month,   pred_iso_month),\n",
    "}\n",
    "# Simple weight grid to find best duration-only mix\n",
    "best_dur_auc, best_dur_w = -1.0, None\n",
    "grid = np.linspace(0,1,11)\n",
    "for wg in grid:           # weight for global\n",
    "    for wc in grid:       # weight for contact\n",
    "        if wg+wc<=1:\n",
    "            wm = 1-(wg+wc)\n",
    "            oof_dur = wg*dur_channels[\"global\"][0] + wc*dur_channels[\"contact\"][0] + wm*dur_channels[\"month\"][0]\n",
    "            auc = roc_auc_score(y_arr, oof_dur)\n",
    "            if auc > best_dur_auc:\n",
    "                best_dur_auc = auc; best_dur_w = (wg,wc,wm)\n",
    "best_oof_dur = best_dur_w[0]*dur_channels[\"global\"][0] + best_dur_w[1]*dur_channels[\"contact\"][0] + best_dur_w[2]*dur_channels[\"month\"][0]\n",
    "best_pred_dur= best_dur_w[0]*dur_channels[\"global\"][1] + best_dur_w[1]*dur_channels[\"contact\"][1] + best_dur_w[2]*dur_channels[\"month\"][1]\n",
    "print(f\"[Iso-DUR*] best OOF AUC={best_dur_auc:.6f} at (w_global={best_dur_w[0]:.2f}, w_contact={best_dur_w[1]:.2f}, w_month={best_dur_w[2]:.2f})\")\n",
    "\n",
    "# A) Submit pure duration isotonic (strong baseline)\n",
    "subA = pd.DataFrame({\"id\": test[\"id\"], \"y\": best_pred_dur})\n",
    "subA.to_csv(\"submission_duration_iso_contact_month.csv\", index=False)\n",
    "print(\"Wrote submission_duration_iso_contact_month.csv\")\n",
    "\n",
    "# 3) Blend duration with boosters — rank vs mean, search weights finely\n",
    "def best_blend_3way(cb_oof, lgb_oof, dur_oof, cb_pred, lgb_pred, dur_pred):\n",
    "    best_auc, best_name, best_test = -1.0, None, None\n",
    "    # mean simplex search (fine grid)\n",
    "    for w_cb in np.linspace(0,1,41):\n",
    "        for w_lgb in np.linspace(0,1,41):\n",
    "            if w_cb + w_lgb <= 1:\n",
    "                w_dur = 1 - (w_cb + w_lgb)\n",
    "                oof = w_cb*cb_oof + w_lgb*lgb_oof + w_dur*dur_oof\n",
    "                auc = roc_auc_score(y_arr, oof)\n",
    "                if auc > best_auc:\n",
    "                    best_auc, best_name, best_test = auc, f\"mean(wcb={w_cb:.3f},wlgb={w_lgb:.3f},wdur={w_dur:.3f})\", \\\n",
    "                        (w_cb*cb_pred + w_lgb*lgb_pred + w_dur*dur_pred)\n",
    "    # rank equal-weights (often robust)\n",
    "    oof_r = (rankit(cb_oof)+rankit(lgb_oof)+rankit(dur_oof))/3.0\n",
    "    auc_r = roc_auc_score(y_arr, oof_r)\n",
    "    if auc_r > best_auc:\n",
    "        best_auc, best_name, best_test = auc_r, \"rank_equal\", \\\n",
    "            (rankit(cb_pred)+rankit(lgb_pred)+rankit(dur_pred))/3.0\n",
    "    print(f\"[Blend3] best OOF AUC={best_auc:.6f} via {best_name}\")\n",
    "    return best_test, best_name, best_auc\n",
    "\n",
    "best_test_blend, best_name_blend, best_auc_blend = best_blend_3way(\n",
    "    cb_oof, lgb_oof, best_oof_dur, cb_pred, lgb_pred, best_pred_dur\n",
    ")\n",
    "subB = pd.DataFrame({\"id\": test[\"id\"], \"y\": best_test_blend})\n",
    "subB.to_csv(\"submission_rank_or_mean_blend_cb_lgb_dur.csv\", index=False)\n",
    "print(\"Wrote submission_rank_or_mean_blend_cb_lgb_dur.csv\")\n",
    "\n",
    "# 4) Proper K-fold meta stack on OOF features (more honest than fitting LR on full OOF)\n",
    "meta_feats_tr = np.column_stack([\n",
    "    cb_oof, lgb_oof, best_oof_dur,\n",
    "    rankit(dur_tr), np.log1p(np.clip(dur_tr,0,None))\n",
    "])\n",
    "meta_feats_te = np.column_stack([\n",
    "    cb_pred, lgb_pred, best_pred_dur,\n",
    "    rankit(dur_te), np.log1p(np.clip(dur_te,0,None))\n",
    "])\n",
    "\n",
    "meta_oof = np.zeros(len(y_arr), dtype=np.float32)\n",
    "meta_pred = np.zeros(len(test), dtype=np.float32)\n",
    "for tr_idx, va_idx in skf.split(meta_feats_tr, y_arr):\n",
    "    m = LogisticRegression(C=3.0, solver=\"lbfgs\", max_iter=500)\n",
    "    m.fit(meta_feats_tr[tr_idx], y_arr[tr_idx])\n",
    "    meta_oof[va_idx] = m.predict_proba(meta_feats_tr[va_idx])[:,1]\n",
    "    meta_pred += m.predict_proba(meta_feats_te)[:,1] / FOLDS\n",
    "auc_meta = roc_auc_score(y_arr, meta_oof)\n",
    "print(f\"[Meta-LR KFold] OOF AUC={auc_meta:.6f}\")\n",
    "subC = pd.DataFrame({\"id\": test[\"id\"], \"y\": meta_pred})\n",
    "subC.to_csv(\"submission_meta_lr_kfold_cb_lgb_dur.csv\", index=False)\n",
    "print(\"Wrote submission_meta_lr_kfold_cb_lgb_dur.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af893b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iso-Global] OOF raw=0.891598 log1p=0.891598 blended=0.891598\n",
      "[Iso-PerContact] OOF AUC=0.500000\n",
      "[Iso-Avg] OOF AUC=0.891598\n",
      "[BLEND+] Best OOF AUC=0.956628 via mean_grid(w_cb=0.1,w_lgb=0.2,w_dur=0.7)\n",
      "Wrote: submission_best_blend_with_duration.csv\n",
      "[META-LR] OOF AUC=0.958436\n",
      "Wrote: submission_meta_lr_cb_lgb_dur.csv\n"
     ]
    }
   ],
   "source": [
    "# # === Duration-centric booster: global iso, per-contact iso, best blend, and a simple stack ===\n",
    "# import numpy as np, pandas as pd\n",
    "# from sklearn.isotonic import IsotonicRegression\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# assert \"duration\" in train.columns, \"duration missing. Rebuild features with DROP_DURATION=False.\"\n",
    "\n",
    "# FOLDS = 10\n",
    "# skf   = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# dur_tr = train[\"duration\"].astype(float).to_numpy()\n",
    "# dur_te = test[\"duration\"].astype(float).to_numpy()\n",
    "# y_arr  = y.values\n",
    "\n",
    "# # ------------------ 1) Global isotonic (raw + log1p, pick/blend) ------------------\n",
    "# oof_raw  = np.zeros_like(dur_tr, dtype=np.float32)\n",
    "# pred_raw = np.zeros_like(dur_te,  dtype=np.float32)\n",
    "# oof_log  = np.zeros_like(dur_tr, dtype=np.float32)\n",
    "# pred_log = np.zeros_like(dur_te,  dtype=np.float32)\n",
    "\n",
    "# for tr_idx, va_idx in skf.split(dur_tr.reshape(-1,1), y_arr):\n",
    "#     # raw\n",
    "#     ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "#     ir.fit(dur_tr[tr_idx], y_arr[tr_idx])\n",
    "#     oof_raw[va_idx]  = ir.predict(dur_tr[va_idx])\n",
    "#     pred_raw        += ir.predict(dur_te) / FOLDS\n",
    "#     # log1p\n",
    "#     xtr = np.log1p(np.clip(dur_tr[tr_idx], 0, None))\n",
    "#     xva = np.log1p(np.clip(dur_tr[va_idx], 0, None))\n",
    "#     xte = np.log1p(np.clip(dur_te,        0, None))\n",
    "#     ir2 = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "#     ir2.fit(xtr, y_arr[tr_idx])\n",
    "#     oof_log[va_idx] = ir2.predict(xva)\n",
    "#     pred_log       += ir2.predict(xte) / FOLDS\n",
    "\n",
    "# auc_raw = roc_auc_score(y_arr, oof_raw)\n",
    "# auc_log = roc_auc_score(y_arr, oof_log)\n",
    "# w_raw = 0.5 if abs(auc_raw-auc_log)<0.002 else (1.0 if auc_raw>auc_log else 0.0)\n",
    "# oof_iso_global  = w_raw*oof_raw + (1-w_raw)*oof_log\n",
    "# pred_iso_global = w_raw*pred_raw + (1-w_raw)*pred_log\n",
    "# print(f\"[Iso-Global] OOF raw={auc_raw:.6f} log1p={auc_log:.6f} blended={roc_auc_score(y_arr,oof_iso_global):.6f}\")\n",
    "\n",
    "# # ------------------ 2) Per-contact isotonic (fallback to global) ------------------\n",
    "# contact_tr = train[\"contact\"].astype(str).fillna(\"NA\").values\n",
    "# contact_te = test[\"contact\"].astype(str).fillna(\"NA\").values\n",
    "# min_group = 2000  # need enough samples to fit stable iso per group\n",
    "\n",
    "# oof_iso_contact = np.zeros_like(dur_tr, dtype=np.float32)\n",
    "# pred_iso_contact = np.zeros_like(dur_te, dtype=np.float32)\n",
    "\n",
    "# for tr_idx, va_idx in skf.split(dur_tr.reshape(-1,1), y_arr):\n",
    "#     # fit a global fallback on fold's train idx\n",
    "#     g_ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "#     g_ir.fit(dur_tr[tr_idx], y_arr[tr_idx])\n",
    "#     # groups in this fold\n",
    "#     groups = np.unique(contact_tr[tr_idx])\n",
    "#     per_group_models = {}\n",
    "#     for g in groups:\n",
    "#         mask = (contact_tr[tr_idx] == g)\n",
    "#         if mask.sum() >= min_group:\n",
    "#             ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "#             ir.fit(dur_tr[tr_idx][mask], y_arr[tr_idx][mask])\n",
    "#             per_group_models[g] = ir\n",
    "#     # OOF preds for this fold\n",
    "#     for g in np.unique(contact_tr[va_idx]):\n",
    "#         mask = (contact_tr[va_idx]==g)\n",
    "#         model = per_group_models.get(g, g_ir)\n",
    "#         oof_iso_contact[va_idx][mask] = model.predict(dur_tr[va_idx][mask])\n",
    "\n",
    "# # For test, fit per-contact on full train (with same fallback)\n",
    "# g_ir_full = IsotonicRegression(out_of_bounds=\"clip\").fit(dur_tr, y_arr)\n",
    "# per_group_full = {}\n",
    "# for g in np.unique(contact_tr):\n",
    "#     mask = (contact_tr==g)\n",
    "#     if mask.sum() >= min_group:\n",
    "#         ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "#         ir.fit(dur_tr[mask], y_arr[mask])\n",
    "#         per_group_full[g] = ir\n",
    "\n",
    "# for g in np.unique(contact_te):\n",
    "#     mask = (contact_te==g)\n",
    "#     model = per_group_full.get(g, g_ir_full)\n",
    "#     pred_iso_contact[mask] = model.predict(dur_te[mask])\n",
    "\n",
    "# print(f\"[Iso-PerContact] OOF AUC={roc_auc_score(y_arr, oof_iso_contact):.6f}\")\n",
    "\n",
    "# # ------------------ 3) Blends including duration models ------------------\n",
    "# def rankit(a):\n",
    "#     return pd.Series(a).rank(method=\"average\").to_numpy() / (len(a)+1e-9)\n",
    "\n",
    "# cands = {}\n",
    "# # two duration channels (global + per-contact) averaged for stability\n",
    "# oof_dur = 0.5*(oof_iso_global + oof_iso_contact)\n",
    "# pred_dur = 0.5*(pred_iso_global + pred_iso_contact)\n",
    "# print(f\"[Iso-Avg] OOF AUC={roc_auc_score(y_arr, oof_dur):.6f}\")\n",
    "\n",
    "# # Baselines you already have\n",
    "# cands[\"mean_cb_lgb\"]     = (0.5*(cb_oof + lgb_oof), 0.5*(cb_pred + lgb_pred))\n",
    "# cands[\"rank_cb_lgb\"]     = (0.5*(rankit(cb_oof)+rankit(lgb_oof)),\n",
    "#                             0.5*(rankit(cb_pred)+rankit(lgb_pred)))\n",
    "\n",
    "# # Add duration into blends\n",
    "# cands[\"mean_cb_lgb_dur\"] = ((cb_oof + lgb_oof + oof_dur)/3.0,\n",
    "#                             (cb_pred + lgb_pred + pred_dur)/3.0)\n",
    "# cands[\"rank_cb_lgb_dur\"] = ((rankit(cb_oof)+rankit(lgb_oof)+rankit(oof_dur))/3.0,\n",
    "#                             (rankit(cb_pred)+rankit(lgb_pred)+rankit(pred_dur))/3.0)\n",
    "\n",
    "# # Simplex grid over 3-way MEAN blend (CB/LGB/DUR)\n",
    "# best_auc, best_name, best_test = -1.0, None, None\n",
    "# weights = np.linspace(0,1,11)  # 0.0..1.0 step 0.1\n",
    "# for w_cb in weights:\n",
    "#     for w_lgb in weights:\n",
    "#         if w_cb + w_lgb <= 1.0:\n",
    "#             w_dur = 1.0 - (w_cb + w_lgb)\n",
    "#             oof_m = w_cb*cb_oof + w_lgb*lgb_oof + w_dur*oof_dur\n",
    "#             auc = roc_auc_score(y_arr, oof_m)\n",
    "#             if auc > best_auc:\n",
    "#                 best_auc, best_name, best_test = auc, f\"mean_grid(w_cb={w_cb:.1f},w_lgb={w_lgb:.1f},w_dur={w_dur:.1f})\", \\\n",
    "#                     (w_cb*cb_pred + w_lgb*lgb_pred + w_dur*pred_dur)\n",
    "\n",
    "# # Compare with rank 3-way blend too\n",
    "# oof_rank3 = (rankit(cb_oof)+rankit(lgb_oof)+rankit(oof_dur))/3.0\n",
    "# auc_rank3 = roc_auc_score(y_arr, oof_rank3)\n",
    "# if auc_rank3 > best_auc:\n",
    "#     best_auc, best_name, best_test = auc_rank3, \"rank_equal_3way\", \\\n",
    "#         (rankit(cb_pred)+rankit(lgb_pred)+rankit(pred_dur))/3.0\n",
    "\n",
    "# print(f\"[BLEND+] Best OOF AUC={best_auc:.6f} via {best_name}\")\n",
    "\n",
    "# sub = pd.DataFrame({\"id\": test[\"id\"], \"y\": best_test})\n",
    "# fname = f\"submission_best_blend_with_duration.csv\"\n",
    "# sub.to_csv(fname, index=False)\n",
    "# print(\"Wrote:\", fname)\n",
    "\n",
    "# # ------------------ 4) Bonus: tiny meta-stack (logistic on OOF) ------------------\n",
    "# # Features to meta: [cb_oof, lgb_oof, oof_dur, duration_rank]\n",
    "# dur_rank = rankit(dur_tr)\n",
    "# meta_X = np.column_stack([cb_oof, lgb_oof, oof_dur, dur_rank])\n",
    "# meta_te = np.column_stack([cb_pred, lgb_pred, pred_dur, rankit(dur_te)])\n",
    "\n",
    "# # CV AUC for meta (honest OOF already available; LR on OOF is okay here)\n",
    "# lr = LogisticRegression(C=2.0, solver=\"lbfgs\", max_iter=500)\n",
    "# lr.fit(meta_X, y_arr)\n",
    "# oof_meta = lr.predict_proba(meta_X)[:,1]\n",
    "# auc_meta = roc_auc_score(y_arr, oof_meta)\n",
    "# pred_meta = lr.predict_proba(meta_te)[:,1]\n",
    "# print(f\"[META-LR] OOF AUC={auc_meta:.6f}\")\n",
    "\n",
    "# sub2 = pd.DataFrame({\"id\": test[\"id\"], \"y\": pred_meta})\n",
    "# sub2_name = \"submission_meta_lr_cb_lgb_dur.csv\"\n",
    "# sub2.to_csv(sub2_name, index=False)\n",
    "# print(\"Wrote:\", sub2_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c88f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 'duration' not in features. Top scores usually include it. Rebuild X with DROP_DURATION=False if you want max AUC.\n",
      "0:\ttest: 0.7929568\tbest: 0.7929568 (0)\ttotal: 51.3ms\tremaining: 10m 14s\n",
      "200:\ttest: 0.8434138\tbest: 0.8434138 (200)\ttotal: 5.67s\tremaining: 5m 32s\n",
      "400:\ttest: 0.8502251\tbest: 0.8502251 (400)\ttotal: 11.5s\tremaining: 5m 34s\n",
      "600:\ttest: 0.8536598\tbest: 0.8536598 (600)\ttotal: 17.4s\tremaining: 5m 29s\n",
      "800:\ttest: 0.8554976\tbest: 0.8554976 (800)\ttotal: 23.2s\tremaining: 5m 23s\n",
      "1000:\ttest: 0.8568576\tbest: 0.8568591 (998)\ttotal: 28.9s\tremaining: 5m 17s\n",
      "1200:\ttest: 0.8577602\tbest: 0.8577602 (1200)\ttotal: 34.7s\tremaining: 5m 11s\n",
      "1400:\ttest: 0.8585213\tbest: 0.8585213 (1400)\ttotal: 40.4s\tremaining: 5m 5s\n",
      "1600:\ttest: 0.8589860\tbest: 0.8589912 (1598)\ttotal: 46.2s\tremaining: 4m 59s\n",
      "1800:\ttest: 0.8594119\tbest: 0.8594119 (1800)\ttotal: 51.9s\tremaining: 4m 53s\n",
      "2000:\ttest: 0.8597962\tbest: 0.8597986 (1997)\ttotal: 57.6s\tremaining: 4m 47s\n",
      "2200:\ttest: 0.8599679\tbest: 0.8599679 (2200)\ttotal: 1m 3s\tremaining: 4m 41s\n",
      "2400:\ttest: 0.8601619\tbest: 0.8601724 (2385)\ttotal: 1m 8s\tremaining: 4m 35s\n",
      "2600:\ttest: 0.8603971\tbest: 0.8603971 (2600)\ttotal: 1m 14s\tremaining: 4m 29s\n",
      "2800:\ttest: 0.8603680\tbest: 0.8603971 (2600)\ttotal: 1m 20s\tremaining: 4m 24s\n",
      "3000:\ttest: 0.8604986\tbest: 0.8605001 (2999)\ttotal: 1m 26s\tremaining: 4m 18s\n",
      "3200:\ttest: 0.8604850\tbest: 0.8605230 (3017)\ttotal: 1m 31s\tremaining: 4m 12s\n",
      "3400:\ttest: 0.8604646\tbest: 0.8605230 (3017)\ttotal: 1m 37s\tremaining: 4m 6s\n",
      "3600:\ttest: 0.8604427\tbest: 0.8605230 (3017)\ttotal: 1m 43s\tremaining: 4m\n",
      "3800:\ttest: 0.8604469\tbest: 0.8605230 (3017)\ttotal: 1m 48s\tremaining: 3m 54s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8605229962\n",
      "bestIteration = 3017\n",
      "\n",
      "Shrink model to first 3018 iterations.\n",
      "[CB] fold 1: AUC=0.860523\n",
      "0:\ttest: 0.7892190\tbest: 0.7892190 (0)\ttotal: 27.7ms\tremaining: 5m 32s\n",
      "200:\ttest: 0.8420940\tbest: 0.8420940 (200)\ttotal: 5.57s\tremaining: 5m 27s\n",
      "400:\ttest: 0.8483383\tbest: 0.8483383 (400)\ttotal: 11.4s\tremaining: 5m 29s\n",
      "600:\ttest: 0.8511525\tbest: 0.8511525 (600)\ttotal: 17.2s\tremaining: 5m 25s\n",
      "800:\ttest: 0.8530000\tbest: 0.8530000 (800)\ttotal: 22.9s\tremaining: 5m 20s\n",
      "1000:\ttest: 0.8540967\tbest: 0.8540967 (1000)\ttotal: 28.8s\tremaining: 5m 16s\n",
      "1200:\ttest: 0.8549195\tbest: 0.8549245 (1194)\ttotal: 34.5s\tremaining: 5m 10s\n",
      "1400:\ttest: 0.8555368\tbest: 0.8555389 (1397)\ttotal: 40.2s\tremaining: 5m 4s\n",
      "1600:\ttest: 0.8559638\tbest: 0.8559638 (1600)\ttotal: 45.9s\tremaining: 4m 58s\n",
      "1800:\ttest: 0.8562042\tbest: 0.8562127 (1798)\ttotal: 51.7s\tremaining: 4m 52s\n",
      "2000:\ttest: 0.8565202\tbest: 0.8565202 (2000)\ttotal: 57.4s\tremaining: 4m 46s\n",
      "2200:\ttest: 0.8567462\tbest: 0.8567467 (2197)\ttotal: 1m 3s\tremaining: 4m 40s\n",
      "2400:\ttest: 0.8569668\tbest: 0.8569728 (2390)\ttotal: 1m 8s\tremaining: 4m 35s\n",
      "2600:\ttest: 0.8570507\tbest: 0.8570863 (2585)\ttotal: 1m 14s\tremaining: 4m 29s\n",
      "2800:\ttest: 0.8571567\tbest: 0.8571567 (2800)\ttotal: 1m 20s\tremaining: 4m 23s\n",
      "3000:\ttest: 0.8571878\tbest: 0.8571959 (2955)\ttotal: 1m 25s\tremaining: 4m 17s\n",
      "3200:\ttest: 0.8572104\tbest: 0.8572273 (3155)\ttotal: 1m 31s\tremaining: 4m 11s\n",
      "3400:\ttest: 0.8571942\tbest: 0.8572424 (3307)\ttotal: 1m 37s\tremaining: 4m 6s\n",
      "3600:\ttest: 0.8571669\tbest: 0.8572424 (3307)\ttotal: 1m 43s\tremaining: 4m\n",
      "3800:\ttest: 0.8571158\tbest: 0.8572424 (3307)\ttotal: 1m 48s\tremaining: 3m 54s\n",
      "4000:\ttest: 0.8571285\tbest: 0.8572424 (3307)\ttotal: 1m 54s\tremaining: 3m 48s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8572424122\n",
      "bestIteration = 3307\n",
      "\n",
      "Shrink model to first 3308 iterations.\n",
      "[CB] fold 2: AUC=0.857242\n",
      "0:\ttest: 0.7879902\tbest: 0.7879902 (0)\ttotal: 26.3ms\tremaining: 5m 15s\n",
      "200:\ttest: 0.8387175\tbest: 0.8387175 (200)\ttotal: 5.56s\tremaining: 5m 26s\n",
      "400:\ttest: 0.8449699\tbest: 0.8449699 (400)\ttotal: 11.3s\tremaining: 5m 28s\n",
      "600:\ttest: 0.8481033\tbest: 0.8481033 (600)\ttotal: 17.1s\tremaining: 5m 24s\n",
      "800:\ttest: 0.8500777\tbest: 0.8500777 (800)\ttotal: 22.9s\tremaining: 5m 20s\n",
      "1000:\ttest: 0.8513675\tbest: 0.8513675 (1000)\ttotal: 28.7s\tremaining: 5m 14s\n",
      "1200:\ttest: 0.8523182\tbest: 0.8523259 (1195)\ttotal: 34.5s\tremaining: 5m 10s\n",
      "1400:\ttest: 0.8529243\tbest: 0.8529243 (1400)\ttotal: 40.3s\tremaining: 5m 5s\n",
      "1600:\ttest: 0.8534583\tbest: 0.8534583 (1600)\ttotal: 46.2s\tremaining: 5m\n",
      "1800:\ttest: 0.8538628\tbest: 0.8538628 (1800)\ttotal: 52.2s\tremaining: 4m 55s\n",
      "2000:\ttest: 0.8541930\tbest: 0.8541962 (1986)\ttotal: 58.1s\tremaining: 4m 50s\n",
      "2200:\ttest: 0.8544505\tbest: 0.8544567 (2182)\ttotal: 1m 4s\tremaining: 4m 45s\n",
      "2400:\ttest: 0.8546409\tbest: 0.8546539 (2380)\ttotal: 1m 10s\tremaining: 4m 39s\n",
      "2600:\ttest: 0.8547643\tbest: 0.8547643 (2600)\ttotal: 1m 16s\tremaining: 4m 34s\n",
      "2800:\ttest: 0.8548808\tbest: 0.8548868 (2797)\ttotal: 1m 22s\tremaining: 4m 29s\n",
      "3000:\ttest: 0.8550221\tbest: 0.8550236 (2999)\ttotal: 1m 28s\tremaining: 4m 25s\n",
      "3200:\ttest: 0.8550808\tbest: 0.8550981 (3147)\ttotal: 1m 34s\tremaining: 4m 19s\n",
      "3400:\ttest: 0.8551611\tbest: 0.8551626 (3385)\ttotal: 1m 39s\tremaining: 4m 12s\n",
      "3600:\ttest: 0.8552295\tbest: 0.8552324 (3582)\ttotal: 1m 45s\tremaining: 4m 6s\n",
      "3800:\ttest: 0.8552332\tbest: 0.8552407 (3631)\ttotal: 1m 51s\tremaining: 3m 59s\n",
      "4000:\ttest: 0.8552044\tbest: 0.8552508 (3904)\ttotal: 1m 57s\tremaining: 3m 54s\n",
      "4200:\ttest: 0.8551634\tbest: 0.8552508 (3904)\ttotal: 2m 2s\tremaining: 3m 47s\n",
      "4400:\ttest: 0.8551366\tbest: 0.8552508 (3904)\ttotal: 2m 8s\tremaining: 3m 41s\n",
      "4600:\ttest: 0.8550794\tbest: 0.8552508 (3904)\ttotal: 2m 14s\tremaining: 3m 35s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8552508231\n",
      "bestIteration = 3904\n",
      "\n",
      "Shrink model to first 3905 iterations.\n",
      "[CB] fold 3: AUC=0.855251\n",
      "0:\ttest: 0.7969290\tbest: 0.7969290 (0)\ttotal: 28.4ms\tremaining: 5m 40s\n",
      "200:\ttest: 0.8390482\tbest: 0.8390482 (200)\ttotal: 5.58s\tremaining: 5m 27s\n",
      "400:\ttest: 0.8450109\tbest: 0.8450109 (400)\ttotal: 11.4s\tremaining: 5m 31s\n",
      "600:\ttest: 0.8480845\tbest: 0.8480845 (600)\ttotal: 17.2s\tremaining: 5m 27s\n",
      "800:\ttest: 0.8498504\tbest: 0.8498504 (800)\ttotal: 23.1s\tremaining: 5m 22s\n",
      "1000:\ttest: 0.8509597\tbest: 0.8509597 (1000)\ttotal: 28.8s\tremaining: 5m 16s\n",
      "1200:\ttest: 0.8516887\tbest: 0.8516920 (1199)\ttotal: 34.5s\tremaining: 5m 10s\n",
      "1400:\ttest: 0.8522606\tbest: 0.8522679 (1397)\ttotal: 40.2s\tremaining: 5m 4s\n",
      "1600:\ttest: 0.8527544\tbest: 0.8527580 (1591)\ttotal: 45.9s\tremaining: 4m 58s\n",
      "1800:\ttest: 0.8531132\tbest: 0.8531132 (1800)\ttotal: 51.7s\tremaining: 4m 52s\n",
      "2000:\ttest: 0.8533443\tbest: 0.8533446 (1999)\ttotal: 57.5s\tremaining: 4m 47s\n",
      "2200:\ttest: 0.8535484\tbest: 0.8535508 (2197)\ttotal: 1m 3s\tremaining: 4m 42s\n",
      "2400:\ttest: 0.8536966\tbest: 0.8537005 (2395)\ttotal: 1m 9s\tremaining: 4m 37s\n",
      "2600:\ttest: 0.8537762\tbest: 0.8537790 (2597)\ttotal: 1m 15s\tremaining: 4m 32s\n",
      "2800:\ttest: 0.8538090\tbest: 0.8538395 (2672)\ttotal: 1m 21s\tremaining: 4m 27s\n",
      "3000:\ttest: 0.8538695\tbest: 0.8538803 (2980)\ttotal: 1m 27s\tremaining: 4m 22s\n",
      "3200:\ttest: 0.8539272\tbest: 0.8539424 (3125)\ttotal: 1m 34s\tremaining: 4m 18s\n",
      "3400:\ttest: 0.8539200\tbest: 0.8539424 (3125)\ttotal: 1m 39s\tremaining: 4m 12s\n",
      "3600:\ttest: 0.8538361\tbest: 0.8539424 (3125)\ttotal: 1m 45s\tremaining: 4m 5s\n",
      "3800:\ttest: 0.8537632\tbest: 0.8539424 (3125)\ttotal: 1m 51s\tremaining: 4m\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8539424479\n",
      "bestIteration = 3125\n",
      "\n",
      "Shrink model to first 3126 iterations.\n",
      "[CB] fold 4: AUC=0.853942\n",
      "0:\ttest: 0.7918425\tbest: 0.7918425 (0)\ttotal: 26.3ms\tremaining: 5m 15s\n",
      "200:\ttest: 0.8414276\tbest: 0.8414276 (200)\ttotal: 5.81s\tremaining: 5m 41s\n",
      "400:\ttest: 0.8472324\tbest: 0.8472324 (400)\ttotal: 11.9s\tremaining: 5m 44s\n",
      "600:\ttest: 0.8497965\tbest: 0.8497965 (600)\ttotal: 18.1s\tremaining: 5m 42s\n",
      "800:\ttest: 0.8512532\tbest: 0.8512532 (800)\ttotal: 24.2s\tremaining: 5m 39s\n",
      "1000:\ttest: 0.8522226\tbest: 0.8522226 (1000)\ttotal: 30.5s\tremaining: 5m 35s\n",
      "1200:\ttest: 0.8528927\tbest: 0.8528927 (1200)\ttotal: 37s\tremaining: 5m 32s\n",
      "1400:\ttest: 0.8533557\tbest: 0.8533557 (1400)\ttotal: 43.4s\tremaining: 5m 28s\n",
      "1600:\ttest: 0.8537020\tbest: 0.8537091 (1595)\ttotal: 49.9s\tremaining: 5m 23s\n",
      "1800:\ttest: 0.8538695\tbest: 0.8538717 (1799)\ttotal: 56.5s\tremaining: 5m 19s\n",
      "2000:\ttest: 0.8540608\tbest: 0.8540633 (1998)\ttotal: 1m 3s\tremaining: 5m 15s\n",
      "2200:\ttest: 0.8541613\tbest: 0.8541769 (2186)\ttotal: 1m 9s\tremaining: 5m 11s\n",
      "2400:\ttest: 0.8542915\tbest: 0.8542915 (2400)\ttotal: 1m 16s\tremaining: 5m 7s\n",
      "2600:\ttest: 0.8543297\tbest: 0.8543445 (2555)\ttotal: 1m 23s\tremaining: 5m 2s\n",
      "2800:\ttest: 0.8542749\tbest: 0.8543445 (2555)\ttotal: 1m 30s\tremaining: 4m 56s\n",
      "3000:\ttest: 0.8542750\tbest: 0.8543445 (2555)\ttotal: 1m 37s\tremaining: 4m 51s\n",
      "3200:\ttest: 0.8542815\tbest: 0.8543445 (2555)\ttotal: 1m 44s\tremaining: 4m 46s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.85434448\n",
      "bestIteration = 2555\n",
      "\n",
      "Shrink model to first 2556 iterations.\n",
      "[CB] fold 5: AUC=0.854344\n",
      "0:\ttest: 0.7935620\tbest: 0.7935620 (0)\ttotal: 26.6ms\tremaining: 5m 19s\n",
      "200:\ttest: 0.8398289\tbest: 0.8398289 (200)\ttotal: 6.4s\tremaining: 6m 15s\n",
      "400:\ttest: 0.8460160\tbest: 0.8460160 (400)\ttotal: 13.1s\tremaining: 6m 17s\n",
      "600:\ttest: 0.8488801\tbest: 0.8488801 (600)\ttotal: 19.8s\tremaining: 6m 15s\n",
      "800:\ttest: 0.8506607\tbest: 0.8506607 (800)\ttotal: 26.6s\tremaining: 6m 12s\n",
      "1000:\ttest: 0.8517981\tbest: 0.8518029 (998)\ttotal: 33.2s\tremaining: 6m 4s\n",
      "1200:\ttest: 0.8525425\tbest: 0.8525425 (1200)\ttotal: 39.7s\tremaining: 5m 56s\n",
      "1400:\ttest: 0.8531003\tbest: 0.8531022 (1399)\ttotal: 46.1s\tremaining: 5m 48s\n",
      "1600:\ttest: 0.8536118\tbest: 0.8536118 (1600)\ttotal: 52.5s\tremaining: 5m 41s\n",
      "1800:\ttest: 0.8539681\tbest: 0.8539681 (1800)\ttotal: 58.9s\tremaining: 5m 33s\n",
      "2000:\ttest: 0.8542320\tbest: 0.8542320 (1999)\ttotal: 1m 5s\tremaining: 5m 25s\n",
      "2200:\ttest: 0.8543977\tbest: 0.8544071 (2185)\ttotal: 1m 11s\tremaining: 5m 18s\n",
      "2400:\ttest: 0.8544724\tbest: 0.8544891 (2387)\ttotal: 1m 17s\tremaining: 5m 10s\n",
      "2600:\ttest: 0.8545473\tbest: 0.8545473 (2600)\ttotal: 1m 24s\tremaining: 5m 3s\n",
      "2800:\ttest: 0.8546152\tbest: 0.8546181 (2799)\ttotal: 1m 30s\tremaining: 4m 56s\n",
      "3000:\ttest: 0.8547192\tbest: 0.8547229 (2998)\ttotal: 1m 36s\tremaining: 4m 48s\n",
      "3200:\ttest: 0.8547406\tbest: 0.8547641 (3113)\ttotal: 1m 42s\tremaining: 4m 41s\n",
      "3400:\ttest: 0.8546862\tbest: 0.8547641 (3113)\ttotal: 1m 48s\tremaining: 4m 34s\n",
      "3600:\ttest: 0.8546717\tbest: 0.8547641 (3113)\ttotal: 1m 54s\tremaining: 4m 27s\n",
      "3800:\ttest: 0.8546838\tbest: 0.8547641 (3113)\ttotal: 2m\tremaining: 4m 20s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8547641138\n",
      "bestIteration = 3113\n",
      "\n",
      "Shrink model to first 3114 iterations.\n",
      "[CB] fold 6: AUC=0.854764\n",
      "0:\ttest: 0.7879694\tbest: 0.7879694 (0)\ttotal: 26.3ms\tremaining: 5m 16s\n",
      "200:\ttest: 0.8376047\tbest: 0.8376047 (200)\ttotal: 5.93s\tremaining: 5m 47s\n",
      "400:\ttest: 0.8437803\tbest: 0.8437803 (400)\ttotal: 12.1s\tremaining: 5m 50s\n",
      "600:\ttest: 0.8466177\tbest: 0.8466177 (600)\ttotal: 18.3s\tremaining: 5m 47s\n",
      "800:\ttest: 0.8484618\tbest: 0.8484618 (800)\ttotal: 24.5s\tremaining: 5m 42s\n",
      "1000:\ttest: 0.8495087\tbest: 0.8495087 (1000)\ttotal: 30.6s\tremaining: 5m 36s\n",
      "1200:\ttest: 0.8503922\tbest: 0.8503922 (1200)\ttotal: 36.7s\tremaining: 5m 29s\n",
      "1400:\ttest: 0.8510951\tbest: 0.8510956 (1398)\ttotal: 42.7s\tremaining: 5m 23s\n",
      "1600:\ttest: 0.8514201\tbest: 0.8514390 (1574)\ttotal: 48.7s\tremaining: 5m 16s\n",
      "1800:\ttest: 0.8516803\tbest: 0.8516803 (1800)\ttotal: 54.7s\tremaining: 5m 9s\n",
      "2000:\ttest: 0.8519883\tbest: 0.8519900 (1999)\ttotal: 1m\tremaining: 5m 3s\n",
      "2200:\ttest: 0.8522337\tbest: 0.8522337 (2200)\ttotal: 1m 6s\tremaining: 4m 56s\n",
      "2400:\ttest: 0.8523708\tbest: 0.8523708 (2400)\ttotal: 1m 12s\tremaining: 4m 50s\n",
      "2600:\ttest: 0.8525575\tbest: 0.8525575 (2600)\ttotal: 1m 18s\tremaining: 4m 43s\n",
      "2800:\ttest: 0.8526507\tbest: 0.8526507 (2800)\ttotal: 1m 24s\tremaining: 4m 37s\n",
      "3000:\ttest: 0.8527751\tbest: 0.8527954 (2908)\ttotal: 1m 30s\tremaining: 4m 31s\n",
      "3200:\ttest: 0.8528073\tbest: 0.8528350 (3060)\ttotal: 1m 36s\tremaining: 4m 24s\n",
      "3400:\ttest: 0.8527821\tbest: 0.8528350 (3060)\ttotal: 1m 42s\tremaining: 4m 18s\n",
      "3600:\ttest: 0.8527594\tbest: 0.8528350 (3060)\ttotal: 1m 48s\tremaining: 4m 12s\n",
      "3800:\ttest: 0.8526675\tbest: 0.8528350 (3060)\ttotal: 1m 54s\tremaining: 4m 6s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8528349799\n",
      "bestIteration = 3060\n",
      "\n",
      "Shrink model to first 3061 iterations.\n",
      "[CB] fold 7: AUC=0.852835\n",
      "0:\ttest: 0.7912664\tbest: 0.7912664 (0)\ttotal: 26.3ms\tremaining: 5m 15s\n",
      "200:\ttest: 0.8419748\tbest: 0.8419748 (200)\ttotal: 5.79s\tremaining: 5m 40s\n",
      "400:\ttest: 0.8477038\tbest: 0.8477038 (400)\ttotal: 11.9s\tremaining: 5m 42s\n",
      "600:\ttest: 0.8505725\tbest: 0.8505725 (600)\ttotal: 17.9s\tremaining: 5m 39s\n",
      "800:\ttest: 0.8522672\tbest: 0.8522672 (800)\ttotal: 23.9s\tremaining: 5m 34s\n",
      "1000:\ttest: 0.8532796\tbest: 0.8532796 (1000)\ttotal: 29.9s\tremaining: 5m 29s\n",
      "1200:\ttest: 0.8540700\tbest: 0.8540729 (1196)\ttotal: 35.9s\tremaining: 5m 23s\n",
      "1400:\ttest: 0.8546780\tbest: 0.8546780 (1400)\ttotal: 41.9s\tremaining: 5m 17s\n",
      "1600:\ttest: 0.8552021\tbest: 0.8552027 (1597)\ttotal: 47.9s\tremaining: 5m 11s\n",
      "1800:\ttest: 0.8555792\tbest: 0.8555792 (1800)\ttotal: 53.8s\tremaining: 5m 4s\n",
      "2000:\ttest: 0.8558113\tbest: 0.8558149 (1999)\ttotal: 59.8s\tremaining: 4m 58s\n",
      "2200:\ttest: 0.8560624\tbest: 0.8560624 (2200)\ttotal: 1m 5s\tremaining: 4m 52s\n",
      "2400:\ttest: 0.8562893\tbest: 0.8562912 (2395)\ttotal: 1m 11s\tremaining: 4m 45s\n",
      "2600:\ttest: 0.8563718\tbest: 0.8563851 (2592)\ttotal: 1m 17s\tremaining: 4m 39s\n",
      "2800:\ttest: 0.8564357\tbest: 0.8564407 (2794)\ttotal: 1m 23s\tremaining: 4m 33s\n",
      "3000:\ttest: 0.8564876\tbest: 0.8564876 (3000)\ttotal: 1m 29s\tremaining: 4m 27s\n",
      "3200:\ttest: 0.8565751\tbest: 0.8565894 (3176)\ttotal: 1m 34s\tremaining: 4m 20s\n",
      "3400:\ttest: 0.8565825\tbest: 0.8566223 (3325)\ttotal: 1m 40s\tremaining: 4m 14s\n",
      "3600:\ttest: 0.8566182\tbest: 0.8566223 (3325)\ttotal: 1m 46s\tremaining: 4m 8s\n",
      "3800:\ttest: 0.8566529\tbest: 0.8566765 (3685)\ttotal: 1m 52s\tremaining: 4m 2s\n",
      "4000:\ttest: 0.8566145\tbest: 0.8566765 (3685)\ttotal: 1m 58s\tremaining: 3m 56s\n",
      "4200:\ttest: 0.8566116\tbest: 0.8566765 (3685)\ttotal: 2m 3s\tremaining: 3m 50s\n",
      "4400:\ttest: 0.8565513\tbest: 0.8566765 (3685)\ttotal: 2m 9s\tremaining: 3m 44s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8566765091\n",
      "bestIteration = 3685\n",
      "\n",
      "Shrink model to first 3686 iterations.\n",
      "[CB] fold 8: AUC=0.856677\n",
      "0:\ttest: 0.7962225\tbest: 0.7962225 (0)\ttotal: 26.6ms\tremaining: 5m 19s\n",
      "200:\ttest: 0.8400612\tbest: 0.8400612 (200)\ttotal: 6.08s\tremaining: 5m 57s\n",
      "400:\ttest: 0.8459397\tbest: 0.8459397 (400)\ttotal: 11.9s\tremaining: 5m 45s\n",
      "600:\ttest: 0.8487680\tbest: 0.8487680 (600)\ttotal: 17.8s\tremaining: 5m 37s\n",
      "800:\ttest: 0.8504024\tbest: 0.8504024 (800)\ttotal: 23.5s\tremaining: 5m 29s\n",
      "1000:\ttest: 0.8515122\tbest: 0.8515122 (1000)\ttotal: 29.3s\tremaining: 5m 22s\n",
      "1200:\ttest: 0.8521851\tbest: 0.8521902 (1197)\ttotal: 35.1s\tremaining: 5m 15s\n",
      "1400:\ttest: 0.8528242\tbest: 0.8528242 (1400)\ttotal: 40.8s\tremaining: 5m 8s\n",
      "1600:\ttest: 0.8532886\tbest: 0.8532920 (1599)\ttotal: 46.5s\tremaining: 5m 2s\n",
      "1800:\ttest: 0.8535382\tbest: 0.8535442 (1791)\ttotal: 52.2s\tremaining: 4m 55s\n",
      "2000:\ttest: 0.8537543\tbest: 0.8537595 (1999)\ttotal: 57.9s\tremaining: 4m 49s\n",
      "2200:\ttest: 0.8539117\tbest: 0.8539117 (2200)\ttotal: 1m 3s\tremaining: 4m 43s\n",
      "2400:\ttest: 0.8540603\tbest: 0.8540666 (2384)\ttotal: 1m 9s\tremaining: 4m 37s\n",
      "2600:\ttest: 0.8542382\tbest: 0.8542382 (2600)\ttotal: 1m 15s\tremaining: 4m 31s\n",
      "2800:\ttest: 0.8543315\tbest: 0.8543484 (2775)\ttotal: 1m 20s\tremaining: 4m 24s\n",
      "3000:\ttest: 0.8543430\tbest: 0.8543646 (2974)\ttotal: 1m 26s\tremaining: 4m 18s\n",
      "3200:\ttest: 0.8544242\tbest: 0.8544435 (3159)\ttotal: 1m 32s\tremaining: 4m 12s\n",
      "3400:\ttest: 0.8545024\tbest: 0.8545283 (3352)\ttotal: 1m 37s\tremaining: 4m 6s\n",
      "3600:\ttest: 0.8545057\tbest: 0.8545283 (3352)\ttotal: 1m 43s\tremaining: 4m\n",
      "3800:\ttest: 0.8544839\tbest: 0.8545407 (3689)\ttotal: 1m 48s\tremaining: 3m 54s\n",
      "4000:\ttest: 0.8544337\tbest: 0.8545407 (3689)\ttotal: 1m 54s\tremaining: 3m 49s\n",
      "4200:\ttest: 0.8543908\tbest: 0.8545407 (3689)\ttotal: 2m\tremaining: 3m 43s\n",
      "4400:\ttest: 0.8544297\tbest: 0.8545407 (3689)\ttotal: 2m 5s\tremaining: 3m 37s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8545407047\n",
      "bestIteration = 3689\n",
      "\n",
      "Shrink model to first 3690 iterations.\n",
      "[CB] fold 9: AUC=0.854541\n",
      "0:\ttest: 0.7927252\tbest: 0.7927252 (0)\ttotal: 27ms\tremaining: 5m 23s\n",
      "200:\ttest: 0.8369182\tbest: 0.8369182 (200)\ttotal: 5.68s\tremaining: 5m 33s\n",
      "400:\ttest: 0.8427570\tbest: 0.8427570 (400)\ttotal: 11.7s\tremaining: 5m 37s\n",
      "600:\ttest: 0.8456961\tbest: 0.8456961 (600)\ttotal: 17.7s\tremaining: 5m 35s\n",
      "800:\ttest: 0.8474213\tbest: 0.8474213 (800)\ttotal: 23.7s\tremaining: 5m 31s\n",
      "1000:\ttest: 0.8485194\tbest: 0.8485194 (1000)\ttotal: 29.9s\tremaining: 5m 28s\n",
      "1200:\ttest: 0.8492274\tbest: 0.8492274 (1200)\ttotal: 36.1s\tremaining: 5m 24s\n",
      "1400:\ttest: 0.8497681\tbest: 0.8497741 (1399)\ttotal: 42.4s\tremaining: 5m 20s\n",
      "1600:\ttest: 0.8501492\tbest: 0.8501492 (1600)\ttotal: 48.9s\tremaining: 5m 17s\n",
      "1800:\ttest: 0.8505313\tbest: 0.8505313 (1800)\ttotal: 55.6s\tremaining: 5m 14s\n",
      "2000:\ttest: 0.8507176\tbest: 0.8507288 (1994)\ttotal: 1m 2s\tremaining: 5m 11s\n",
      "2200:\ttest: 0.8509252\tbest: 0.8509332 (2172)\ttotal: 1m 9s\tremaining: 5m 7s\n",
      "2400:\ttest: 0.8510248\tbest: 0.8510411 (2394)\ttotal: 1m 15s\tremaining: 5m 3s\n",
      "2600:\ttest: 0.8510956\tbest: 0.8511080 (2549)\ttotal: 1m 22s\tremaining: 4m 59s\n",
      "2800:\ttest: 0.8511258\tbest: 0.8511405 (2631)\ttotal: 1m 29s\tremaining: 4m 54s\n",
      "3000:\ttest: 0.8510830\tbest: 0.8511850 (2883)\ttotal: 1m 36s\tremaining: 4m 50s\n",
      "3200:\ttest: 0.8512090\tbest: 0.8512090 (3200)\ttotal: 1m 43s\tremaining: 4m 44s\n",
      "3400:\ttest: 0.8511961\tbest: 0.8512594 (3280)\ttotal: 1m 50s\tremaining: 4m 39s\n",
      "3600:\ttest: 0.8511616\tbest: 0.8512594 (3280)\ttotal: 1m 57s\tremaining: 4m 33s\n",
      "3800:\ttest: 0.8511324\tbest: 0.8512594 (3280)\ttotal: 2m 4s\tremaining: 4m 27s\n",
      "4000:\ttest: 0.8510238\tbest: 0.8512594 (3280)\ttotal: 2m 10s\tremaining: 4m 21s\n",
      "Stopped by overfitting detector  (800 iterations wait)\n",
      "\n",
      "bestTest = 0.8512594474\n",
      "bestIteration = 3280\n",
      "\n",
      "Shrink model to first 3281 iterations.\n",
      "[CB] fold 10: AUC=0.851259\n",
      "[CB] OOF AUC=0.855125  (time 1298.4s)\n",
      "[LGBM] fold 1: AUC=0.863093\n",
      "[LGBM] fold 2: AUC=0.859909\n",
      "[LGBM] fold 3: AUC=0.857978\n",
      "[LGBM] fold 4: AUC=0.857280\n",
      "[LGBM] fold 5: AUC=0.858320\n",
      "[LGBM] fold 6: AUC=0.856628\n",
      "[LGBM] fold 7: AUC=0.855780\n",
      "[LGBM] fold 8: AUC=0.859655\n",
      "[LGBM] fold 9: AUC=0.858080\n",
      "[LGBM] fold 10: AUC=0.854382\n",
      "[LGBM] OOF AUC=0.858107  (time 1527.7s)\n",
      "[BLEND] Best OOF AUC=0.858316 using rank (w_cb=0.200)\n",
      "Wrote: submission_cb_lgb_rank_blend_final.csv\n"
     ]
    }
   ],
   "source": [
    "# # === FINAL MODE: CatBoost + LightGBM + best-of mean/rank blend (full data, 10-fold) ===\n",
    "# import os, time, numpy as np, pandas as pd\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from catboost import CatBoostClassifier, Pool\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# # Sanity: ensure 'duration' is in features (this comp rewards it)\n",
    "# if \"duration\" not in X.columns:\n",
    "#     print(\"⚠️ 'duration' not in features. Top scores usually include it. \"\n",
    "#           \"Rebuild X with DROP_DURATION=False if you want max AUC.\")\n",
    "\n",
    "# # Keep your Mac cooler\n",
    "# avail = os.cpu_count() or 8\n",
    "# threads = min(max(avail - 2, 6), 12)\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = str(threads)\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = str(threads)\n",
    "\n",
    "# FOLDS = 10\n",
    "# RANDOM_STATE = 42\n",
    "\n",
    "# # ---------- CatBoost (full strength CPU preset) ----------\n",
    "# cb_params = dict(\n",
    "#     loss_function=\"Logloss\",\n",
    "#     eval_metric=\"AUC\",\n",
    "#     iterations=12000,            # ES will trim\n",
    "#     learning_rate=0.03,\n",
    "#     depth=8,\n",
    "#     l2_leaf_reg=20,\n",
    "#     random_strength=0.2,\n",
    "#     bootstrap_type=\"Bayesian\",\n",
    "#     bagging_temperature=1.0,\n",
    "#     rsm=0.8,\n",
    "#     one_hot_max_size=64,\n",
    "#     max_ctr_complexity=2,\n",
    "#     border_count=254,\n",
    "#     auto_class_weights=\"Balanced\",\n",
    "#     early_stopping_rounds=800,\n",
    "#     random_seed=RANDOM_STATE,\n",
    "#     thread_count=threads,\n",
    "#     verbose=200,\n",
    "#     allow_writing_files=False\n",
    "# )\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "# cb_oof = np.zeros(len(X), dtype=np.float32)\n",
    "# cb_pred = np.zeros(len(X_test), dtype=np.float32)\n",
    "\n",
    "# t0 = time.time()\n",
    "# for fold, (tr, va) in enumerate(skf.split(X, y), 1):\n",
    "#     X_tr, y_tr = X.iloc[tr], y.iloc[tr]\n",
    "#     X_va, y_va = X.iloc[va], y.iloc[va]\n",
    "\n",
    "#     model = CatBoostClassifier(**cb_params)\n",
    "#     model.fit(\n",
    "#         Pool(X_tr, y_tr, cat_features=cat_idx),\n",
    "#         eval_set=Pool(X_va, y_va, cat_features=cat_idx),\n",
    "#         use_best_model=True\n",
    "#     )\n",
    "\n",
    "#     cb_oof[va] = model.predict_proba(X_va)[:,1]\n",
    "#     cb_pred   += model.predict_proba(Pool(X_test, cat_features=cat_idx))[:,1] / FOLDS\n",
    "#     print(f\"[CB] fold {fold}: AUC={roc_auc_score(y_va, cb_oof[va]):.6f}\")\n",
    "# cb_oof_auc = roc_auc_score(y, cb_oof)\n",
    "# print(f\"[CB] OOF AUC={cb_oof_auc:.6f}  (time {time.time()-t0:.1f}s)\")\n",
    "\n",
    "# # ---------- LightGBM (strong CPU preset with cat smoothing) ----------\n",
    "# X_lgb = X.copy(); X_test_lgb = X_test.copy()\n",
    "# for c in cat_cols:\n",
    "#     X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "#     X_test_lgb[c] = X_test_lgb[c].astype(\"category\")\n",
    "\n",
    "# lgb_params = dict(\n",
    "#     objective=\"binary\",\n",
    "#     boosting_type=\"gbdt\",\n",
    "#     metric=\"auc\",\n",
    "#     learning_rate=0.02,\n",
    "#     n_estimators=40000,            # ES trims\n",
    "#     num_leaves=255,\n",
    "#     max_depth=-1,\n",
    "#     min_data_in_leaf=40,\n",
    "#     feature_fraction=0.8,\n",
    "#     bagging_fraction=0.8,\n",
    "#     bagging_freq=1,\n",
    "#     lambda_l1=1.0, lambda_l2=2.0,\n",
    "#     max_bin=255,\n",
    "#     min_data_per_group=50,\n",
    "#     cat_l2=20.0, cat_smooth=20.0,  # categorical smoothing\n",
    "#     force_col_wise=True,\n",
    "#     deterministic=True,\n",
    "#     n_jobs=threads,\n",
    "#     verbose=-1\n",
    "# )\n",
    "\n",
    "# lgb_oof = np.zeros(len(X_lgb), dtype=np.float32)\n",
    "# lgb_pred = np.zeros(len(X_test_lgb), dtype=np.float32)\n",
    "\n",
    "# t1 = time.time()\n",
    "# for fold, (tr, va) in enumerate(skf.split(X_lgb, y), 1):\n",
    "#     X_tr, y_tr = X_lgb.iloc[tr], y.iloc[tr]\n",
    "#     X_va, y_va = X_lgb.iloc[va], y.iloc[va]\n",
    "\n",
    "#     lgbm = lgb.LGBMClassifier(**lgb_params)\n",
    "#     lgbm.fit(\n",
    "#         X_tr, y_tr,\n",
    "#         eval_set=[(X_va, y_va)],\n",
    "#         eval_metric=\"auc\",\n",
    "#         categorical_feature=cat_cols,\n",
    "#         callbacks=[lgb.early_stopping(stopping_rounds=1200, verbose=False)]\n",
    "#     )\n",
    "#     lgb_oof[va] = lgbm.predict_proba(X_va)[:,1]\n",
    "#     lgb_pred   += lgbm.predict_proba(X_test_lgb)[:,1] / FOLDS\n",
    "#     print(f\"[LGBM] fold {fold}: AUC={roc_auc_score(y_va, lgb_oof[va]):.6f}\")\n",
    "# lgb_oof_auc = roc_auc_score(y, lgb_oof)\n",
    "# print(f\"[LGBM] OOF AUC={lgb_oof_auc:.6f}  (time {time.time()-t1:.1f}s)\")\n",
    "\n",
    "# # ---------- Best-of mean vs rank blend ----------\n",
    "# def rankit(a):\n",
    "#     return pd.Series(a).rank(method=\"average\").to_numpy() / (len(a) + 1e-9)\n",
    "\n",
    "# best_auc, best_name, best_w = -1.0, None, None\n",
    "# for w in np.linspace(0, 1, 41):  # 0.00..1.00 step 0.025\n",
    "#     oof_mean = w*cb_oof + (1-w)*lgb_oof\n",
    "#     auc_mean = roc_auc_score(y, oof_mean)\n",
    "#     if auc_mean > best_auc:\n",
    "#         best_auc, best_name, best_w = auc_mean, f\"mean (w_cb={w:.3f})\", w\n",
    "#     oof_rank = w*rankit(cb_oof) + (1-w)*rankit(lgb_oof)\n",
    "#     auc_rank = roc_auc_score(y, oof_rank)\n",
    "#     if auc_rank > best_auc:\n",
    "#         best_auc, best_name, best_w = auc_rank, f\"rank (w_cb={w:.3f})\", w\n",
    "\n",
    "# print(f\"[BLEND] Best OOF AUC={best_auc:.6f} using {best_name}\")\n",
    "# use_rank = best_name.startswith(\"rank\")\n",
    "# test_blend = best_w*(rankit(cb_pred) if use_rank else cb_pred) + \\\n",
    "#              (1-best_w)*(rankit(lgb_pred) if use_rank else lgb_pred)\n",
    "\n",
    "# # ---------- Submission ----------\n",
    "# sub = pd.DataFrame({\"id\": test[\"id\"], \"y\": test_blend})\n",
    "# fname = f\"submission_cb_lgb_{'rank' if use_rank else 'mean'}_blend_final.csv\"\n",
    "# sub.to_csv(fname, index=False)\n",
    "# print(\"Wrote:\", fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165e74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_COL: id | TARGET: y\n",
      "train shape: (750000, 25) | test shape: (250000, 24)\n"
     ]
    }
   ],
   "source": [
    "# # === Checkpoint: make sure data & key column names are defined ===\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Load if not already loaded in this kernel\n",
    "# DATA_DIR = Path(\"./data\")\n",
    "# if \"train\" not in globals():\n",
    "#     train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "# if \"test\" not in globals():\n",
    "#     test  = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "\n",
    "# # Detect id/target columns robustly\n",
    "# ID_COL = next((c for c in [\"id\",\"Id\",\"ID\"] if c in train.columns), None)\n",
    "# TARGET = next((c for c in [\"y\",\"target\",\"label\"] if c in train.columns), None)\n",
    "\n",
    "# assert ID_COL is not None and TARGET is not None, \n",
    "#     f\"Could not find id/target columns in train. Columns: {list(train.columns)}\"\n",
    "\n",
    "# print(\"ID_COL:\", ID_COL, \"| TARGET:\", TARGET)\n",
    "# print(\"train shape:\", train.shape, \"| test shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb88ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 22 features → 16 categorical / 6 numeric. DROP_DURATION=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Toggle: safer baseline is to drop 'duration'. Try both.\n",
    "# DROP_DURATION = True\n",
    "# features = [c for c in train.columns if c not in [ID_COL, TARGET]]\n",
    "# if DROP_DURATION and \"duration\" in features:\n",
    "#     features.remove(\"duration\")\n",
    "\n",
    "# def infer_cats(df, cols, max_int_card=30):\n",
    "#     cats, nums = [], []\n",
    "#     for c in cols:\n",
    "#         if df[c].dtype == \"object\":\n",
    "#             cats.append(c)\n",
    "#         elif pd.api.types.is_integer_dtype(df[c]) and df[c].nunique() <= max_int_card:\n",
    "#             cats.append(c)\n",
    "#         else:\n",
    "#             nums.append(c)\n",
    "#     return cats, nums\n",
    "\n",
    "# cat_cols, num_cols = infer_cats(train, features)\n",
    "\n",
    "# # Cast categoricals to str for CatBoost; LightGBM will accept category dtype later\n",
    "# for c in cat_cols:\n",
    "#     train[c] = train[c].astype(\"str\")\n",
    "#     test[c]  = test[c].astype(\"str\")\n",
    "\n",
    "# X      = train[features].copy()\n",
    "# y      = train[TARGET].astype(int).copy()\n",
    "# X_test = test[features].copy()\n",
    "\n",
    "# cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
    "# print(f\"Using {len(features)} features → {len(cat_cols)} categorical / {len(num_cols)} numeric. DROP_DURATION={DROP_DURATION}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6ff22",
   "metadata": {},
   "source": [
    "## 6. CatBoost (CPU) — Stratified K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d783bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"6\"   # or 4\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = \"6\"   # or 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949faac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Fast & Strong: CatBoost + LightGBM + Smart Blend (macOS CPU) ===\n",
    "# import os, time, numpy as np, pandas as pd\n",
    "# from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from catboost import CatBoostClassifier, Pool\n",
    "# import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0729d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------- Dev vs Final switch ----------\n",
    "# DEV_MODE = True     # True = quick iteration; False = full strength for final\n",
    "# FOLDS    = 3 if DEV_MODE else 5\n",
    "\n",
    "# # ---------- CPU hygiene ----------\n",
    "# avail = os.cpu_count() or 8\n",
    "# threads = min(max(avail - 2, 4), 8)  # leave headroom for macOS; cap at 8\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = str(threads)\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = str(threads)\n",
    "\n",
    "# # Optional: train on a subset in dev to iterate quickly (keeps class balance)\n",
    "# if DEV_MODE:\n",
    "#     sss = StratifiedShuffleSplit(n_splits=1, test_size=0.6, random_state=42)  # keep 40%\n",
    "#     keep_idx, _ = next(sss.split(X, y))\n",
    "#     X_run, y_run = X.iloc[keep_idx], y.iloc[keep_idx]\n",
    "# else:\n",
    "#     X_run, y_run = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7702030\tbest: 0.7702030 (0)\ttotal: 11.3ms\tremaining: 45.2s\n",
      "200:\ttest: 0.8381570\tbest: 0.8381570 (200)\ttotal: 1.79s\tremaining: 33.9s\n",
      "400:\ttest: 0.8438095\tbest: 0.8438095 (400)\ttotal: 3.5s\tremaining: 31.4s\n",
      "600:\ttest: 0.8459956\tbest: 0.8459956 (600)\ttotal: 5.21s\tremaining: 29.5s\n",
      "800:\ttest: 0.8473366\tbest: 0.8473409 (790)\ttotal: 6.95s\tremaining: 27.8s\n",
      "1000:\ttest: 0.8480945\tbest: 0.8480991 (993)\ttotal: 8.64s\tremaining: 25.9s\n",
      "1200:\ttest: 0.8485436\tbest: 0.8485505 (1167)\ttotal: 10.3s\tremaining: 24.1s\n",
      "1400:\ttest: 0.8486800\tbest: 0.8486877 (1398)\ttotal: 12s\tremaining: 22.3s\n",
      "1600:\ttest: 0.8487266\tbest: 0.8488507 (1487)\ttotal: 13.7s\tremaining: 20.6s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.8488507412\n",
      "bestIteration = 1487\n",
      "\n",
      "Shrink model to first 1488 iterations.\n",
      "[CB] fold 1: AUC=0.848851\n",
      "0:\ttest: 0.7665027\tbest: 0.7665027 (0)\ttotal: 9.82ms\tremaining: 39.3s\n",
      "200:\ttest: 0.8407328\tbest: 0.8407328 (200)\ttotal: 1.73s\tremaining: 32.6s\n",
      "400:\ttest: 0.8463732\tbest: 0.8463732 (400)\ttotal: 3.47s\tremaining: 31.2s\n",
      "600:\ttest: 0.8485682\tbest: 0.8485750 (599)\ttotal: 5.2s\tremaining: 29.4s\n",
      "800:\ttest: 0.8494339\tbest: 0.8494339 (800)\ttotal: 6.98s\tremaining: 27.9s\n",
      "1000:\ttest: 0.8499763\tbest: 0.8499763 (1000)\ttotal: 8.72s\tremaining: 26.1s\n",
      "1200:\ttest: 0.8502532\tbest: 0.8503056 (1156)\ttotal: 10.4s\tremaining: 24.3s\n",
      "1400:\ttest: 0.8503456\tbest: 0.8503544 (1320)\ttotal: 12.1s\tremaining: 22.4s\n",
      "1600:\ttest: 0.8503649\tbest: 0.8504477 (1510)\ttotal: 13.8s\tremaining: 20.7s\n",
      "1800:\ttest: 0.8503584\tbest: 0.8504477 (1510)\ttotal: 15.6s\tremaining: 19s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.8504476909\n",
      "bestIteration = 1510\n",
      "\n",
      "Shrink model to first 1511 iterations.\n",
      "[CB] fold 2: AUC=0.850448\n",
      "0:\ttest: 0.7696640\tbest: 0.7696640 (0)\ttotal: 8.57ms\tremaining: 34.3s\n",
      "200:\ttest: 0.8420578\tbest: 0.8420578 (200)\ttotal: 1.69s\tremaining: 31.9s\n",
      "400:\ttest: 0.8469247\tbest: 0.8469247 (400)\ttotal: 3.41s\tremaining: 30.6s\n",
      "600:\ttest: 0.8489491\tbest: 0.8489491 (600)\ttotal: 5.08s\tremaining: 28.7s\n",
      "800:\ttest: 0.8500399\tbest: 0.8500419 (798)\ttotal: 6.87s\tremaining: 27.4s\n",
      "1000:\ttest: 0.8505999\tbest: 0.8505999 (1000)\ttotal: 8.73s\tremaining: 26.2s\n",
      "1200:\ttest: 0.8510117\tbest: 0.8510117 (1200)\ttotal: 10.4s\tremaining: 24.3s\n",
      "1400:\ttest: 0.8510948\tbest: 0.8511291 (1283)\ttotal: 12.1s\tremaining: 22.5s\n",
      "1600:\ttest: 0.8510529\tbest: 0.8511408 (1416)\ttotal: 13.8s\tremaining: 20.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.8511407573\n",
      "bestIteration = 1416\n",
      "\n",
      "Shrink model to first 1417 iterations.\n",
      "[CB] fold 3: AUC=0.851141\n",
      "[CB] OOF AUC=0.850116  (time 48.7s)\n"
     ]
    }
   ],
   "source": [
    "# # ---------- CatBoost (lighter/faster for mac CPU) ----------\n",
    "# cb_params = dict(\n",
    "#     loss_function=\"Logloss\",\n",
    "#     eval_metric=\"AUC\",\n",
    "#     iterations=4000 if DEV_MODE else 8000,\n",
    "#     learning_rate=0.05 if DEV_MODE else 0.035,\n",
    "#     depth=6 if DEV_MODE else 8,\n",
    "#     l2_leaf_reg=20,\n",
    "#     random_strength=0.2,\n",
    "#     bootstrap_type=\"Bernoulli\",             # faster than Bayesian on CPU\n",
    "#     subsample=0.8,                           # row subsampling\n",
    "#     rsm=0.7,                                 # col subsampling\n",
    "#     one_hot_max_size=32 if DEV_MODE else 64,\n",
    "#     max_ctr_complexity=1 if DEV_MODE else 2,\n",
    "#     border_count=128 if DEV_MODE else 254,   # fewer bins -> faster\n",
    "#     early_stopping_rounds=300 if DEV_MODE else 600,\n",
    "#     auto_class_weights=\"Balanced\",\n",
    "#     thread_count=threads,\n",
    "#     random_seed=42,\n",
    "#     verbose=200,\n",
    "#     allow_writing_files=False\n",
    "# )\n",
    "\n",
    "# skf_cb = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "# cb_oof = np.zeros(len(X_run), dtype=np.float32)\n",
    "# cb_pred = np.zeros(len(X_test), dtype=np.float32)\n",
    "\n",
    "# t0 = time.time()\n",
    "# for f, (tr, va) in enumerate(skf_cb.split(X_run, y_run), 1):\n",
    "#     X_tr, y_tr = X_run.iloc[tr], y_run.iloc[tr]\n",
    "#     X_va, y_va = X_run.iloc[va], y_run.iloc[va]\n",
    "#     model = CatBoostClassifier(**cb_params)\n",
    "#     model.fit(\n",
    "#         Pool(X_tr, y_tr, cat_features=cat_idx),\n",
    "#         eval_set=Pool(X_va, y_va, cat_features=cat_idx),\n",
    "#         use_best_model=True\n",
    "#     )\n",
    "#     cb_oof[va] = model.predict_proba(X_va)[:,1]\n",
    "#     cb_pred += model.predict_proba(Pool(X_test, cat_features=cat_idx))[:,1] / FOLDS\n",
    "#     print(f\"[CB] fold {f}: AUC={roc_auc_score(y_va, cb_oof[va]):.6f}\")\n",
    "# cb_oof_auc = roc_auc_score(y_run, cb_oof)\n",
    "# print(f\"[CB] OOF AUC={cb_oof_auc:.6f}  (time {time.time()-t0:.1f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7787472\tbest: 0.7787472 (0)\ttotal: 24.3ms\tremaining: 1m 37s\n",
      "200:\ttest: 0.8412393\tbest: 0.8412393 (200)\ttotal: 4.38s\tremaining: 1m 22s\n",
      "400:\ttest: 0.8472951\tbest: 0.8472951 (400)\ttotal: 8.77s\tremaining: 1m 18s\n",
      "600:\ttest: 0.8499414\tbest: 0.8499414 (600)\ttotal: 13.2s\tremaining: 1m 14s\n",
      "800:\ttest: 0.8515696\tbest: 0.8515696 (800)\ttotal: 17.6s\tremaining: 1m 10s\n",
      "1000:\ttest: 0.8525174\tbest: 0.8525174 (1000)\ttotal: 22s\tremaining: 1m 5s\n",
      "1200:\ttest: 0.8532080\tbest: 0.8532086 (1198)\ttotal: 26.4s\tremaining: 1m 1s\n",
      "1400:\ttest: 0.8536296\tbest: 0.8536296 (1400)\ttotal: 30.7s\tremaining: 57s\n",
      "1600:\ttest: 0.8539648\tbest: 0.8539648 (1600)\ttotal: 35.1s\tremaining: 52.6s\n",
      "1800:\ttest: 0.8542443\tbest: 0.8542443 (1800)\ttotal: 39.5s\tremaining: 48.2s\n",
      "2000:\ttest: 0.8543972\tbest: 0.8543972 (2000)\ttotal: 43.9s\tremaining: 43.8s\n",
      "2200:\ttest: 0.8544883\tbest: 0.8544969 (2183)\ttotal: 48.2s\tremaining: 39.4s\n",
      "2400:\ttest: 0.8545722\tbest: 0.8545722 (2400)\ttotal: 52.5s\tremaining: 35s\n",
      "2600:\ttest: 0.8545553\tbest: 0.8545752 (2406)\ttotal: 56.9s\tremaining: 30.6s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.8545751834\n",
      "bestIteration = 2406\n",
      "\n",
      "Shrink model to first 2407 iterations.\n",
      "[CB] Fold 1: AUC=0.854575\n",
      "0:\ttest: 0.7820100\tbest: 0.7820100 (0)\ttotal: 21.6ms\tremaining: 1m 26s\n",
      "200:\ttest: 0.8406783\tbest: 0.8406783 (200)\ttotal: 4.35s\tremaining: 1m 22s\n",
      "400:\ttest: 0.8460452\tbest: 0.8460452 (400)\ttotal: 8.81s\tremaining: 1m 19s\n",
      "600:\ttest: 0.8483944\tbest: 0.8483944 (600)\ttotal: 13.2s\tremaining: 1m 14s\n",
      "800:\ttest: 0.8497179\tbest: 0.8497193 (799)\ttotal: 17.6s\tremaining: 1m 10s\n",
      "1000:\ttest: 0.8506199\tbest: 0.8506199 (1000)\ttotal: 22s\tremaining: 1m 5s\n",
      "1200:\ttest: 0.8511506\tbest: 0.8511506 (1200)\ttotal: 26.4s\tremaining: 1m 1s\n",
      "1400:\ttest: 0.8515352\tbest: 0.8515352 (1400)\ttotal: 30.7s\tremaining: 57s\n",
      "1600:\ttest: 0.8518604\tbest: 0.8518619 (1599)\ttotal: 35s\tremaining: 52.5s\n",
      "1800:\ttest: 0.8520469\tbest: 0.8520469 (1800)\ttotal: 39.6s\tremaining: 48.3s\n",
      "2000:\ttest: 0.8521229\tbest: 0.8521268 (1964)\ttotal: 44s\tremaining: 43.9s\n",
      "2200:\ttest: 0.8522251\tbest: 0.8522251 (2200)\ttotal: 48.3s\tremaining: 39.5s\n",
      "2400:\ttest: 0.8522841\tbest: 0.8522899 (2383)\ttotal: 52.6s\tremaining: 35s\n",
      "2600:\ttest: 0.8523068\tbest: 0.8523114 (2567)\ttotal: 56.9s\tremaining: 30.6s\n",
      "2800:\ttest: 0.8523202\tbest: 0.8523313 (2777)\ttotal: 1m 1s\tremaining: 26.2s\n",
      "3000:\ttest: 0.8522606\tbest: 0.8523313 (2777)\ttotal: 1m 5s\tremaining: 21.8s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.8523313286\n",
      "bestIteration = 2777\n",
      "\n",
      "Shrink model to first 2778 iterations.\n",
      "[CB] Fold 2: AUC=0.852331\n",
      "0:\ttest: 0.7798326\tbest: 0.7798326 (0)\ttotal: 20.7ms\tremaining: 1m 22s\n",
      "200:\ttest: 0.8397817\tbest: 0.8397817 (200)\ttotal: 4.39s\tremaining: 1m 22s\n",
      "400:\ttest: 0.8455084\tbest: 0.8455084 (400)\ttotal: 8.76s\tremaining: 1m 18s\n",
      "600:\ttest: 0.8479819\tbest: 0.8479819 (600)\ttotal: 13.1s\tremaining: 1m 14s\n",
      "800:\ttest: 0.8493009\tbest: 0.8493009 (800)\ttotal: 17.5s\tremaining: 1m 9s\n",
      "1000:\ttest: 0.8501335\tbest: 0.8501335 (1000)\ttotal: 21.9s\tremaining: 1m 5s\n",
      "1200:\ttest: 0.8507516\tbest: 0.8507516 (1200)\ttotal: 26.2s\tremaining: 1m 1s\n",
      "1400:\ttest: 0.8511974\tbest: 0.8511974 (1400)\ttotal: 30.5s\tremaining: 56.7s\n",
      "1600:\ttest: 0.8514989\tbest: 0.8514994 (1599)\ttotal: 35s\tremaining: 52.4s\n",
      "1800:\ttest: 0.8516897\tbest: 0.8516976 (1797)\ttotal: 39.3s\tremaining: 48s\n",
      "2000:\ttest: 0.8518774\tbest: 0.8518817 (1998)\ttotal: 43.6s\tremaining: 43.6s\n",
      "2200:\ttest: 0.8519427\tbest: 0.8519554 (2140)\ttotal: 48s\tremaining: 39.2s\n",
      "2400:\ttest: 0.8520486\tbest: 0.8520513 (2314)\ttotal: 52.3s\tremaining: 34.8s\n",
      "2600:\ttest: 0.8520794\tbest: 0.8520978 (2538)\ttotal: 56.7s\tremaining: 30.5s\n",
      "2800:\ttest: 0.8521352\tbest: 0.8521373 (2799)\ttotal: 1m\tremaining: 26.1s\n",
      "3000:\ttest: 0.8521159\tbest: 0.8521569 (2835)\ttotal: 1m 5s\tremaining: 21.7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.8521569237\n",
      "bestIteration = 2835\n",
      "\n",
      "Shrink model to first 2836 iterations.\n",
      "[CB] Fold 3: AUC=0.852157\n",
      "\n",
      "[CB] OOF AUC=0.853007 | folds: 0.85458, 0.85233, 0.85216\n",
      "Time: 199.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>19.898697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poutcome</th>\n",
       "      <td>10.605021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>10.070681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>8.510089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_idx</th>\n",
       "      <td>8.447581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>7.947882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>5.872536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>4.790214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>4.100690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>3.548862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>3.218665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_cap</th>\n",
       "      <td>2.728230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>2.243687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>1.723223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>1.561792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance_sign</th>\n",
       "      <td>1.475043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_bin</th>\n",
       "      <td>0.966355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays_bin</th>\n",
       "      <td>0.729259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.681744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.434470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays_is_neg1</th>\n",
       "      <td>0.350174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_previous</th>\n",
       "      <td>0.095106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance\n",
       "balance         19.898697\n",
       "poutcome        10.605021\n",
       "day             10.070681\n",
       "month            8.510089\n",
       "month_idx        8.447581\n",
       "contact          7.947882\n",
       "age              5.872536\n",
       "housing          4.790214\n",
       "pdays            4.100690\n",
       "campaign         3.548862\n",
       "job              3.218665\n",
       "campaign_cap     2.728230\n",
       "marital          2.243687\n",
       "loan             1.723223\n",
       "education        1.561792\n",
       "balance_sign     1.475043\n",
       "age_bin          0.966355\n",
       "pdays_bin        0.729259\n",
       "previous         0.681744\n",
       "default          0.434470\n",
       "pdays_is_neg1    0.350174\n",
       "has_previous     0.095106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# import numpy as np, time\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# N_FOLDS, RANDOM_STATE = 5, 42\n",
    "\n",
    "# cb_params = dict(\n",
    "#     loss_function=\"Logloss\",\n",
    "#     eval_metric=\"AUC\",\n",
    "#     iterations=4000,            # was 12000\n",
    "#     learning_rate=0.05,         # a bit faster per-iter\n",
    "#     depth=6,                    # shallower trees\n",
    "#     l2_leaf_reg=20,\n",
    "#     random_strength=0.2,\n",
    "#     bootstrap_type=\"Bernoulli\", # cheaper than Bayesian\n",
    "#     subsample=0.8,              # row subsampling\n",
    "#     rsm=0.7,                    # column subsampling\n",
    "#     one_hot_max_size=32,\n",
    "#     max_ctr_complexity=1,\n",
    "#     border_count=128,           # fewer bins → faster\n",
    "#     early_stopping_rounds=300,\n",
    "#     auto_class_weights=\"Balanced\",\n",
    "#     thread_count=6,             # match OMP/MKL\n",
    "#     random_seed=42,\n",
    "#     verbose=200,\n",
    "#     allow_writing_files=False\n",
    "# )\n",
    "# N_FOLDS = 3  # use 3 folds while iterating; switch back to 5–10 for final\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "# cb_oof = np.zeros(len(X), dtype=np.float32)\n",
    "# cb_pred = np.zeros(len(X_test), dtype=np.float32)\n",
    "# fold_aucs = []\n",
    "\n",
    "# start = time.time()\n",
    "# for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "#     X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "#     X_va, y_va = X.iloc[va_idx], y.iloc[va_idx]\n",
    "\n",
    "#     train_pool = Pool(X_tr, y_tr, cat_features=cat_idx)\n",
    "#     valid_pool = Pool(X_va, y_va, cat_features=cat_idx)\n",
    "#     test_pool  = Pool(X_test,      cat_features=cat_idx)\n",
    "\n",
    "#     model = CatBoostClassifier(**cb_params)\n",
    "#     model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "#     cb_oof[va_idx] = model.predict_proba(valid_pool)[:, 1]\n",
    "#     cb_pred += model.predict_proba(test_pool)[:, 1] / N_FOLDS\n",
    "\n",
    "#     auc = roc_auc_score(y_va, cb_oof[va_idx])\n",
    "#     fold_aucs.append(auc)\n",
    "#     print(f\"[CB] Fold {fold}: AUC={auc:.6f}\")\n",
    "\n",
    "# oof_auc = roc_auc_score(y, cb_oof)\n",
    "# print(f\"\\n[CB] OOF AUC={oof_auc:.6f} | folds: {', '.join(f'{a:.5f}' for a in fold_aucs)}\")\n",
    "# print(f\"Time: {time.time()-start:.1f}s\")\n",
    "\n",
    "# # Save OOF for later blends\n",
    "# import pandas as pd\n",
    "# pd.DataFrame({ID_COL: train[ID_COL], TARGET: y, \"oof_cb\": cb_oof}).to_csv(\n",
    "#     f\"oof_catboost_{'noDur' if DROP_DURATION else 'withDur'}.csv\", index=False\n",
    "# )\n",
    "\n",
    "# # Feature importance (PredictionValuesChange)\n",
    "# importances = pd.Series(model.get_feature_importance(type=\"PredictionValuesChange\"), index=X.columns)               .sort_values(ascending=False)\n",
    "# display(importances.head(25).to_frame(\"importance\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25394ad",
   "metadata": {},
   "source": [
    "## 7. LightGBM (CPU, native categoricals) — Stratified K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db268ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] fold 1: AUC=0.850863\n",
      "[LGBM] fold 2: AUC=0.854482\n",
      "[LGBM] fold 3: AUC=0.853723\n",
      "[LGBM] OOF AUC=0.853002  (time 72.1s)\n"
     ]
    }
   ],
   "source": [
    "# # ---------- LightGBM (fast + categorical smoothing) ----------\n",
    "# # Ensure category dtype for LGBM\n",
    "# X_lgb = X_run.copy(); X_test_lgb = X_test.copy()\n",
    "# for c in cat_cols:\n",
    "#     X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "#     X_test_lgb[c] = X_test_lgb[c].astype(\"category\")\n",
    "\n",
    "# lgb_params = dict(\n",
    "#     objective=\"binary\",\n",
    "#     boosting_type=\"gbdt\",\n",
    "#     metric=\"auc\",\n",
    "#     learning_rate=0.03 if DEV_MODE else 0.025,\n",
    "#     n_estimators=10000 if DEV_MODE else 20000,  # early stopping trims\n",
    "#     num_leaves=63 if DEV_MODE else 127,\n",
    "#     max_depth=-1,\n",
    "#     min_data_in_leaf=80 if DEV_MODE else 60,\n",
    "#     feature_fraction=0.8,\n",
    "#     bagging_fraction=0.8,\n",
    "#     bagging_freq=1,\n",
    "#     lambda_l1=1.0, lambda_l2=2.0,\n",
    "#     max_bin=255,\n",
    "#     # categorical smoothing knobs:\n",
    "#     min_data_per_group=50,\n",
    "#     cat_l2=10.0, cat_smooth=10.0,\n",
    "#     # speed:\n",
    "#     force_col_wise=True,\n",
    "#     deterministic=True,\n",
    "#     n_jobs=threads,\n",
    "#     verbose=-1\n",
    "# )\n",
    "\n",
    "# skf_lgb = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "# lgb_oof = np.zeros(len(X_lgb), dtype=np.float32)\n",
    "# lgb_pred = np.zeros(len(X_test_lgb), dtype=np.float32)\n",
    "\n",
    "# t1 = time.time()\n",
    "# for f, (tr, va) in enumerate(skf_lgb.split(X_lgb, y_run), 1):\n",
    "#     X_tr, y_tr = X_lgb.iloc[tr], y_run.iloc[tr]\n",
    "#     X_va, y_va = X_lgb.iloc[va], y_run.iloc[va]\n",
    "#     lgbm = lgb.LGBMClassifier(**lgb_params)\n",
    "#     lgbm.fit(\n",
    "#         X_tr, y_tr,\n",
    "#         eval_set=[(X_va, y_va)],\n",
    "#         eval_metric=\"auc\",\n",
    "#         categorical_feature=cat_cols,\n",
    "#         callbacks=[lgb.early_stopping(stopping_rounds=600 if DEV_MODE else 800, verbose=False)]\n",
    "#     )\n",
    "#     lgb_oof[va] = lgbm.predict_proba(X_va)[:,1]\n",
    "#     lgb_pred += lgbm.predict_proba(X_test_lgb)[:,1] / FOLDS\n",
    "#     print(f\"[LGBM] fold {f}: AUC={roc_auc_score(y_va, lgb_oof[va]):.6f}\")\n",
    "# lgb_oof_auc = roc_auc_score(y_run, lgb_oof)\n",
    "# print(f\"[LGBM] OOF AUC={lgb_oof_auc:.6f}  (time {time.time()-t1:.1f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32384363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 1: 0.860405\n",
      "[LGBM] Fold 2: 0.857053\n",
      "[LGBM] Fold 3: 0.857265\n",
      "[LGBM] Fold 4: 0.857450\n",
      "[LGBM] Fold 5: 0.855750\n",
      "[LGBM] OOF AUC: 0.857582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np, pandas as pd\n",
    "\n",
    "# # Ensure categorical dtype for LightGBM\n",
    "# X_lgb = X.copy()\n",
    "# X_test_lgb = X_test.copy()\n",
    "# for c in cat_cols:\n",
    "#     X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "#     X_test_lgb[c] = X_test_lgb[c].astype(\"category\")\n",
    "\n",
    "# lgb_params = dict(\n",
    "#     objective=\"binary\", metric=\"auc\",\n",
    "#     learning_rate=0.03, n_estimators=10000,\n",
    "#     num_leaves=63, min_data_in_leaf=80,\n",
    "#     feature_fraction=0.8, bagging_fraction=0.8, bagging_freq=1,\n",
    "#     lambda_l1=1.0, lambda_l2=2.0,\n",
    "#     max_bin=255, n_jobs=6, verbose=-1\n",
    "# )\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# lgb_oof = np.zeros(len(X_lgb), dtype=np.float32)\n",
    "# lgb_pred = np.zeros(len(X_test_lgb), dtype=np.float32)\n",
    "# fold_aucs_lgb = []\n",
    "\n",
    "# for fold, (tr, va) in enumerate(skf.split(X_lgb, y), 1):\n",
    "#     X_tr, y_tr = X_lgb.iloc[tr], y.iloc[tr]\n",
    "#     X_va, y_va = X_lgb.iloc[va], y.iloc[va]\n",
    "#     lgbm = lgb.LGBMClassifier(**lgb_params)\n",
    "#     lgbm.fit(\n",
    "#         X_tr, y_tr,\n",
    "#         eval_set=[(X_va, y_va)],\n",
    "#         eval_metric=\"auc\",\n",
    "#         categorical_feature=cat_cols,\n",
    "#         callbacks=[lgb.early_stopping(stopping_rounds=800, verbose=False)]\n",
    "#     )\n",
    "#     lgb_oof[va] = lgbm.predict_proba(X_va)[:,1]\n",
    "#     lgb_pred += lgbm.predict_proba(X_test_lgb)[:,1] / skf.n_splits\n",
    "#     auc = roc_auc_score(y_va, lgb_oof[va]); fold_aucs_lgb.append(auc)\n",
    "#     print(f\"[LGBM] Fold {fold}: {auc:.6f}\")\n",
    "\n",
    "# print(f\"[LGBM] OOF AUC: {roc_auc_score(y, lgb_oof):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76dbf5",
   "metadata": {},
   "source": [
    "## 8. Blend (CatBoost + LightGBM) & Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BLEND] Best OOF AUC=0.853226 using rank (w_cb=0.20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # ---------- Mean vs Rank blend; pick best on OOF ----------\n",
    "# def rankit(a):\n",
    "#     # Stable rank in [0,1]\n",
    "#     return pd.Series(a).rank(method=\"average\").to_numpy() / (len(a) + 1e-9)\n",
    "\n",
    "# best_auc, best_name, best_w = -1.0, None, None\n",
    "# for w in np.linspace(0, 1, 21):\n",
    "#     # mean blend\n",
    "#     oof_mean = w*cb_oof + (1-w)*lgb_oof\n",
    "#     auc_mean = roc_auc_score(y_run, oof_mean)\n",
    "#     if auc_mean > best_auc:\n",
    "#         best_auc, best_name, best_w = auc_mean, f\"mean (w_cb={w:.2f})\", w\n",
    "#     # rank blend\n",
    "#     oof_rank = w*rankit(cb_oof) + (1-w)*rankit(lgb_oof)\n",
    "#     auc_rank = roc_auc_score(y_run, oof_rank)\n",
    "#     if auc_rank > best_auc:\n",
    "#         best_auc, best_name, best_w = auc_rank, f\"rank (w_cb={w:.2f})\", w\n",
    "\n",
    "# print(f\"[BLEND] Best OOF AUC={best_auc:.6f} using {best_name}\")\n",
    "\n",
    "# # Build test preds with the same strategy\n",
    "# use_rank = best_name.startswith(\"rank\")\n",
    "# if use_rank:\n",
    "#     test_blend = best_w*rankit(cb_pred) + (1-best_w)*rankit(lgb_pred)\n",
    "# else:\n",
    "#     test_blend = best_w*cb_pred + (1-best_w)*lgb_pred\n",
    "\n",
    "# # If we trained on a subset in DEV_MODE, rebuild full-data models quickly for test preds (optional).\n",
    "# # (Often not needed; you can just switch DEV_MODE=False for your final run.)\n",
    "# # -- Skipping here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: submission_cb_lgb_rank_blend.csv\n"
     ]
    }
   ],
   "source": [
    "# # ---------- Write submission ----------\n",
    "# sub = pd.DataFrame({\"id\": test[\"id\"], \"y\": test_blend})\n",
    "# fname = f\"submission_cb_lgb_{'rank' if use_rank else 'mean'}_blend.csv\"\n",
    "# sub.to_csv(fname, index=False)\n",
    "# print(\"Wrote:\", fname)\n",
    "\n",
    "# # ---------- (Optional) Persist OOF from full set if not in DEV_MODE ----------\n",
    "# if not DEV_MODE:\n",
    "#     pd.DataFrame({ID_COL: train.loc[X_run.index, ID_COL], TARGET: y_run, \n",
    "#                   \"oof_cb\": cb_oof, \"oof_lgb\": lgb_oof}).to_csv(\n",
    "#         f\"oof_cb_lgb_{'rank' if use_rank else 'mean'}_blend.csv\", index=False\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3bb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BLEND] Best OOF AUC = 0.857638 at w_cb=0.05, w_lgb=0.95\n",
      "Wrote: submission_cb_lgb_blend.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000</td>\n",
       "      <td>0.045683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750001</td>\n",
       "      <td>0.088430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750002</td>\n",
       "      <td>0.102545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750003</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750004</td>\n",
       "      <td>0.227797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         y\n",
       "0  750000  0.045683\n",
       "1  750001  0.088430\n",
       "2  750002  0.102545\n",
       "3  750003  0.001105\n",
       "4  750004  0.227797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# import numpy as np, pandas as pd\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# # Grid-search a simple linear weight on OOF\n",
    "# best_w, best_auc = None, -1.0\n",
    "# for w in np.linspace(0, 1, 21):\n",
    "#     oof_blend = w*cb_oof + (1-w)*lgb_oof\n",
    "#     auc = roc_auc_score(y, oof_blend)\n",
    "#     if auc > best_auc:\n",
    "#         best_auc, best_w = auc, w\n",
    "\n",
    "# print(f\"[BLEND] Best OOF AUC = {best_auc:.6f} at w_cb={best_w:.2f}, w_lgb={1-best_w:.2f}\")\n",
    "\n",
    "# # Apply the same weight to test preds\n",
    "# test_blend = best_w*cb_pred + (1-best_w)*lgb_pred\n",
    "\n",
    "# sub = pd.DataFrame({\"id\": test[\"id\"], \"y\": test_blend})\n",
    "# sub_path = \"submission_cb_lgb_blend.csv\"\n",
    "# sub.to_csv(sub_path, index=False)\n",
    "# print(\"Wrote:\", sub_path)\n",
    "# display(sub.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fbab8",
   "metadata": {},
   "source": [
    "## 9. (Optional) PyTorch MLP using Apple GPU (MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af006de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ⚠️ Note: Tree boosters usually outperform simple MLPs on tabular data.\n",
    "# # This section is just to demonstrate Apple GPU (MPS) usage on macOS.\n",
    "# # If you want best AUC, rely on CatBoost/LightGBM above.\n",
    "\n",
    "# import numpy as np, pandas as pd\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# device = torch.device(\"mps\") if (hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()) else          torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Using device:\", device)\n",
    "\n",
    "# # Build a preprocessing pipeline: one-hot categoricals, pass-through numerics\n",
    "# ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "# pre = ColumnTransformer(\n",
    "#     transformers=[(\"ohe\", ohe, cat_cols)],\n",
    "#     remainder=\"passthrough\"\n",
    "# )\n",
    "\n",
    "# # Fit on full train, transform to sparse -> dense (careful with memory; data here is moderate)\n",
    "# X_all = pre.fit_transform(X)\n",
    "# X_test_all = pre.transform(X_test)\n",
    "\n",
    "# # Convert to torch tensors (use float32)\n",
    "# import scipy.sparse as sp\n",
    "# if sp.issparse(X_all):\n",
    "#     X_all = X_all.astype(np.float32).toarray()\n",
    "#     X_test_all = X_test_all.astype(np.float32).toarray()\n",
    "# else:\n",
    "#     X_all = X_all.astype(np.float32)\n",
    "#     X_test_all = X_test_all.astype(np.float32)\n",
    "\n",
    "# X_all_t = torch.tensor(X_all, dtype=torch.float32)\n",
    "# y_all_t = torch.tensor(y.values, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "# def make_mlp(in_dim):\n",
    "#     return nn.Sequential(\n",
    "#         nn.Linear(in_dim, 256), nn.ReLU(),\n",
    "#         nn.Linear(256, 128), nn.ReLU(),\n",
    "#         nn.Linear(128, 64), nn.ReLU(),\n",
    "#         nn.Linear(64, 1), nn.Sigmoid()\n",
    "#     )\n",
    "\n",
    "# # 5-fold CV for MLP (quick)\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# mlp_oof = np.zeros(len(X_all), dtype=np.float32)\n",
    "# mlp_pred = np.zeros(len(X_test_all), dtype=np.float32)\n",
    "\n",
    "# for fold, (tr_idx, va_idx) in enumerate(skf.split(X_all, y), 1):\n",
    "#     model = make_mlp(X_all.shape[1]).to(device)\n",
    "#     opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "#     bce = nn.BCELoss()\n",
    "\n",
    "#     tr_ds = TensorDataset(X_all_t[tr_idx], y_all_t[tr_idx])\n",
    "#     va_ds = TensorDataset(X_all_t[va_idx], y_all_t[va_idx])\n",
    "#     tr_dl = DataLoader(tr_ds, batch_size=4096, shuffle=True)\n",
    "#     va_dl = DataLoader(va_ds, batch_size=8192, shuffle=False)\n",
    "\n",
    "#     best_auc, best_state = 0.0, None\n",
    "#     for epoch in range(15):  # short training\n",
    "#         model.train()\n",
    "#         for xb, yb in tr_dl:\n",
    "#             xb, yb = xb.to(device), yb.to(device)\n",
    "#             pred = model(xb)\n",
    "#             loss = bce(pred, yb)\n",
    "#             opt.zero_grad(); loss.backward(); opt.step()\n",
    "#         # quick eval\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             all_preds = []\n",
    "#             for xb, yb in va_dl:\n",
    "#                 xb = xb.to(device)\n",
    "#                 all_preds.append(model(xb).detach().cpu().numpy())\n",
    "#             va_p = np.vstack(all_preds).ravel()\n",
    "#         auc = roc_auc_score(y_all_t[va_idx].numpy(), va_p)\n",
    "#         if auc > best_auc:\n",
    "#             best_auc, best_state = auc, model.state_dict()\n",
    "#         # print(f\"Fold {fold} Epoch {epoch+1}: AUC={auc:.4f}\")\n",
    "#     if best_state:\n",
    "#         model.load_state_dict(best_state)\n",
    "\n",
    "#     # Save OOF for fold\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         va_dl = DataLoader(va_ds, batch_size=8192, shuffle=False)\n",
    "#         all_preds = []\n",
    "#         for xb, yb in va_dl:\n",
    "#             xb = xb.to(device)\n",
    "#             all_preds.append(model(xb).detach().cpu().numpy())\n",
    "#         mlp_oof[va_idx] = np.vstack(all_preds).ravel()\n",
    "\n",
    "#     # Test preds\n",
    "#     Xt_t = torch.tensor(X_test_all, dtype=torch.float32)\n",
    "#     t_dl = DataLoader(TensorDataset(Xt_t, torch.zeros(len(Xt_t),1)), batch_size=8192, shuffle=False)\n",
    "#     with torch.no_grad():\n",
    "#         all_preds = []\n",
    "#         for xb, _ in t_dl:\n",
    "#             xb = xb.to(device)\n",
    "#             all_preds.append(model(xb).detach().cpu().numpy())\n",
    "#         mlp_pred += np.vstack(all_preds).ravel() / skf.n_splits\n",
    "\n",
    "# print(\"[MLP] OOF AUC:\", roc_auc_score(y, mlp_oof))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
